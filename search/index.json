[{"content":" 오늘은 드디어 그 유명한 쿠버네티스!!!\n쿠버만 잘해도 반은 간다는데\n화이팅! 부셔보자!!!\nKubenetes(K8S) 설명 컨테이너화된 애플리케이션 배포, 확장 및 관리를 자동화 하는 오픈소스 시스템 대규모 애플리케이션을 신뢰성 있고 효율적인 운영을 도움 특징 서비스 디스커버리 및 로드 밸런싱 : DNS 혹은 자체 IP를 사용해 컨테이너 노출(컨테이너에 트랙픽이 많으면 로드밸런싱 후 배포하여 안정적으로 운영 가능) 스토리지 오케스트레이션 : 로컬저장소, 클라우드 공급자 등과 같이 원하는 저장소 시스템 사용 가능 자동화된 롤아웃, 롤백 : 배포된 컨테이너의 원하는 상태 서술 및 현재 원하는 상태로 변경 자동화된 빈패킹 : 컨테이너 노드에 맞춰 리소스를 가장 잘 사용할 수 있도록 지원 자동화된 복구 : 실패한 컨테이너를 다시 시작, 교체하며 사용자가 정의한 상태 이외에는 지속적으로 복구 가능 시크릿과 구성관리 : 암초, OAuth 토큰, SSH 키와 같은 중요한 정보를 저장 및 관리(컨테이너 이미지 재구성하지 않고 시크릿 및 애플리케이션 구성을 배포 및 업데이트) 핵심 개념 cluster : 여러 대의 머신(노드)으로 구성된 그룹(마스터 노드와 여러 워커 노드로 구성) node : 클러스터 구성요소가 되는 물리적 또는 가상머신 pod : k8s가 생성하고 관리할 수 있는 배포 가능한 가장 작은 단워(하나 이상의 컨테이너 그룹) replicaset : 동일한 포드의 복제본을 일정하게 유지해 가용성 보장 시 사용되는 리소스(Deploment 사용 권장) deployment : 파드와 레플리카셋에 대한 선언적 업데이트 제공 statefulset : 관리하는 데 사용되는 워크로드, 파드 순서 및 고유성 보장(Deployment와 다르게 동자성 유지) Daemonset : 모든 노드가 파드의 사본을 실행(모든 노드에서 클러스터 스토리지, 로그 수집, 노드 모니터링 데몬 실행) Job : 하나 이상의 파드를 생성하고 종료될 때 까지 계속 파드 실행 시도 Cronjob : 반복 일정에 따라 Job 생성 Namespace : 클러스터 내에 리소스를 논리적으로 분리 실습 실습 1 UTM 3개 생성 후 각각 접속 1 2 3 4 5 6 7 8 9 10 11 # 쿠버네티스 설치 sudo snap install microk8s --classic --channel=1.30 # alias 등록 alias kubectl=\u0026#39;microk8s kubectl\u0026#39; # 2번 생성해서 각각 접속 microk8s add-node # Worker Node 연결 정보 확인 kubectl get nodes 실습 2 Master에서 워커 노드로 분배해주기 때문에 별도 config 설정이 없다면 master에서 하지 못한다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 테스트 폴더 생성 및 접속 mkdir kubenetes \u0026amp;\u0026amp; cd kubenetes # pod, Replicaset, Deployment, Job, CornJob, Daemonset 생성 vi \u0026lt;파일명\u0026gt;.yml # 생성한 파일 실행 kubectl apply -f \u0026lt;파일명\u0026gt; # 생성한 정보 확인 kubectl get \u0026lt;리소스\u0026gt; -A -o wide # 생성 안될 때 확인 kubectl describe pod \u0026lt;pod 이름\u0026gt; 실습 3 kubectl 명령어 익히기 차이점 비교 Create vs Apply Create : 리소스 새로 생성시 사용, 이미 존재하는 리소스를 업데이트하지 않음 Apply : 리소스를 생성 혹은 업데이트시 사용, 변경 사항을 클러스터에 적용 시 유용 Log vs Describe Log : Pod 로그를 출력해 디버깅 정보 제공 Describe : 리소스 상태와 이벤트를 포함한 상세 정보 출력 patch vs edit patch : 리소스를 Json이나 Yml 패치 형식으로 부분 업데이트 시 사용 edit : 리소스를 직접 편집 시 사용, 편집 후 저장 시 변경사항 적용 1 # 테스트 폴더 생성 및 접속 ","date":"2024-07-22T21:27:45+09:00","permalink":"https://choiseungwoo98.github.io/p/k8s-kubernetes-%EA%B8%B0%EC%B4%88/","title":"[K8S] Kubernetes 기초"},{"content":" 오늘은 배포 자동화에 대해 배웠다.\n거의 대부분의 프로젝트가 자동화를 사용하는 만큼 집중해서 잘 들어야지 잊지 않기 위해 복습 또 복습\u0026hellip;\nIaC(Infrastructure As Code) 서버, 네트워크, DB, 애플리케이션 구성 등 IT 인프라를 수동 관리 대신 코드로 정의하고 관리하는 방식 프로그래밍 언어, 구성 파일을 사용하여 인프라 자동 배포 및 관리 특징 자동화, 일관성 : 수동 오류를 줄이고 배포, 관리의 일관성 유지 버전 관리 : 변경 이력 추적 및 복구 가능 재사용성 : 코드 모듈화 및 템플릿화 를 통해 재사용성을 높여 비용 절감 협업 : Devops 문화의 핵심 요소 가시성, 투명성 : 모든 설정을 명시적으로 정의해, 인프라 구성 상태를 명확히 파악 구현 방식 선언적 접근 방식 : 원하는 최종 상태 정의, 시스템 자동 구성(Terraform, AWS CloudFormation 등), 간결한 설정으로 이해가 쉽고 필요한 설정만 변경 명령적 접근 방식 : 수행할 명령어 순서 명시 및 인프라 설정을 위한 단계별 명령 작성(Ansible, Chef 등), 세부적인 제어 가능, 복잡한 논리와 조건 처리를 쉽게 구현 도구 Terraform : 클라우드 인프라를 코드로 정의하는 오픈소스 도구 AWS CloudFormation : AWS 리소스 템플릿으로 정의하여 배포 Ansible : 서버 구성 및 애플리케이션 배포 자동화 도구, YAML 포맷의 플레이북 사용 Kubernetes : 컨테이너화된 애플리케이션 배포, 스케일링, 운영 자동화, Yaml 파일을 통해 클러스터 상태 관리 워크플로우 계획 : 요구사항 분석 및 인프라 구조 설계 코드 작성 : 인프라를 코드로 정의 버전 관리 : 작성된 코드를 Git 등의 버전 관리 시스템에 저장 및 이력 관리 테스트 : 테스트 환경에서 코드 실행 및 결과 검증 적용 : 검증된 코드를 실제 환경에 배포 모니터링, 관리 : 배포된 인프라 모니터링 및 수정, 업데이트 장점 신속한 배포 : 자동화된 프로세스를 통해 신속하게 배포 효율성 : 반복적인 작업을 자동화 일관성 : 모든 환경에서 동일한 설정 적용 복구 능력 : 코드 기반 인프라는 장애 시 빠르게 복구 가능 확장성 : 필요에 따라 쉽게 확장 및 축소 가능 Terraform 인프라를 코드로 관리하는 도구, HashiCorp에서 개발 인프라를 선언적으로 정의 및 관리 대부분 인프라를 테라폼해서 배포, 진짜 중요한 사업인 경우 손으로 배포 특징 프로바이더 : AWS, Azure, GCP 등 다양한 클라우드 서비스 제공자 지원 인프라 코드화 : JSON과 유사한 HCL(HashiCorp Configuration Language) 사용 실행 계획 : 변경사항 적용 전 계획 미리 확인 모듈화 : 재사용 가능한 모듈 사용 워크플로우 init : 프로젝트 디렉토리 초기화 및 필요한 플러그인 다운로드 plan : 변경 사항 시뮬레이션 및 계획서 제출 apply : 계획된 변경 사항 실제 인프라 적용 state : 인프라 상태 확인 및 관리 destroy : 인프라 자원 제거 예제 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # CSP 설정 provider \u0026#34;aws\u0026#34; { # 할당 지역 설정 region = \u0026#34;ap-northeast-2\u0026#34; } # 변수 설정 variable \u0026#34;instance_count\u0026#34; { # 기본 값 설정 default = 3 } # CSP 내부에서 사용할 리소스 명칭 resource \u0026#34;aws_instance\u0026#34; \u0026#34;example\u0026#34; { ami = \u0026#34;ami-123456\u0026#34; instance_type = \u0026#34;t2.micro\u0026#34; } # 오브젝트의 특정 항목을 파일로 출력 output \u0026#34;instance_ip\u0026#34; { value = aws_instance.example.public_ip } Ansible IT 자동화 도구로 서버 구성 관리, 애플리케이션 배포, 작업 자동화 지원 원격에서 수백, 수천대 까지 명령어를 한번에 실행해 모든 자동화 가능 특징 Agentless : SSH를 통해 연결 진행 모듈 기반 : 모듈을 통해 다양한 작업 수행 YAML : 가독성 높은 YAML 포맷 사용 확장성 : 커뮤니티 모듈 및 플러그인을 통해 기능 확장 가능 구성요소 Inventory : 관리할 호스트 목록 정의 Playbook : 작업 정의서(YAML 포맷 사용), 실질적인 명령 수행 부분 Modules : 특정 작업을 수행하는 코드 블록 Roles : 관련 작업을 그룹화하여 재사용 Tasks : 실행할 작업 정의 Handlers : 특정 조건에 따라 실행되느 작업 Templates : Jinja2 템플릿을 통해 설정 파일 생성 워크플로우 인벤토리 작성 : 호스트 목록 작성 플레이북 작성 : 수행할 작업을 정의한 YAML 파일 작성 작업 실행 : 플레이북 실행 상태 확인 : 호스트 상태 및 관리 실습 유저 생성(AdminstratorAccess) 액세스키 생성(CLI) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # 액세스 키 등록 # 액세스키, 비밀 액세스 키, 리전, 타입 - json 추천 입력 aws configure # 설정 확인 cat ~/.aws/credentials # main.tf 파일 생성 후 붙여넣기(키 위치 밑 ip 변경) vi main.tf # 현재 디렉토리에 있는 Terraform 구성 파일 초기화 및 필요한 플러그인, 모듈 다운로드 terraform init # 현재 구성 파일 기반으로 실행 계획 생성 및 적용될 변경 사항 확인 terraform plan # 실행 계획을 실제로 적용하여 인프라 생성 혹은 업데이트 terraform apply # hosts.ini 파일에 문구 추가 echo \u0026#34;[webservers]\u0026#34; \u0026gt; hosts.ini # Terraform 출력 값에서 인스턴스 IP를 json 형식으로 가져와 hosts.ini 파일에 적용 terraform output -json instance_ips | jq -r \u0026#39;.[]\u0026#39; \u0026gt;\u0026gt; hosts.ini # playbook.yml 파일 생성 vi playbook.yml # ansible.cfg 파일 생성 vi ansible.cfg # hosts.ini 파일을 인벤토리로 사용하여 Ansible 플레이북 실행 ansible-playbook -i hosts.ini playbook.yml # ssh 접속 ssh -i \u0026lt;key\u0026gt; \u0026lt;os\u0026gt;@\u0026lt;ip\u0026gt; # 실행 중인 모든 프로세서 중 nginx 필터링 ps -ef | grep nginx # Terraform 구성을 기반으로 인프라를 제거 terraform destroy ","date":"2024-07-18T09:54:15+09:00","permalink":"https://choiseungwoo98.github.io/p/iac-iac-%EA%B8%B0%EC%B4%88-%EB%B0%8F-terraform-ansible/","title":"[IaC] IaC 기초 및 Terraform, Ansible"},{"content":" 오늘은 EBS, 람다와 EFS에 대해 배웠다 잊지 않기 위해 복습 또 복습\u0026hellip;\nEBS(Elastic Block Storage) AWS 블록 스토리지 서비스로 EC2 인스턴스에 사용되는 지속적인 스토리지 DB, 파일 시스템, 로그 스토리지, 애플리케이션 데이터 등 사용 데이터를 블록 단위로 저장하며 개별적으로 다루어 질 수 있다. 지속성이 보장되며 중지 또는 종료해도 데이터 유지 주로 자주 접근하지 않는 데이터를 저렴하게 저장할 때 사용한다. 특징 탄력성 : 필요에 따라 크기 조정, 스냅샷을 통해 백업 및 복원 가능(용량을 늘리는 건 쉬우나 줄이는 건 힘들어 충분히 고려 후 증설) 고성능 : 다양한 선능 옵션 제공 내구성 : 데이터 복제 및 높은 가용성 제공 보안 : IAM 정책을 통한 접근 제어 가능 스냅샷 : 볼륨의 시점 복사본 생성 가능 S3에 저장되며 복구 가능 실습(볼륨 확장) 인스턴스 생성 보안 그룹 권한 변경 볼륨 늘림 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 인스턴스 접근 ssh -i \u0026lt;aws key\u0026gt; \u0026lt;os\u0026gt;@\u0026lt;ip\u0026gt; # 루트 권한으로 변경 sudo su # 파일 시스템 디스크 사용량 노출 df -hT # 시스템 블록 장치 나열 lsblk # 지정된 파티션의 크기 확장 growpart /dev/xvda 1 # XFS 파일 시스템 크기 확장 xfs_growfs /dev/xvda1 # 증설 확인 lsblk AWS EFS(Elastic FileSystem) 여러 EC2 인스턴스가 동시에 데이터를 읽고 쓰며, 파일 시스템의 확장성과 고가용성 보장 같은 VPC 내에서 여러 인스턴스가 같은 파일 시스템에 접근해 읽기, 쓰기 가능 특징 확장성 : 파일 시스템 크기 자동 조절 및 필요에 따른 확장, 축소 가능 고가용성 및 내구성 : 여러 가용 영역(AZ)에 데이터 자동 복제해 높은 가용성 및 내구성 제공 동시 엑세스 : 여러 EC2 인스턴스에서 동시에 엑세스 할 수 있으며 공유 파일 시스템이 필요한 워크 로드에 적합 실습(볼륨 확장) EFS 생성 보안그룹 수정 연결 1 2 3 4 5 6 7 8 9 10 11 12 13 # 인스턴스 접근 ssh -i \u0026lt;aws key\u0026gt; \u0026lt;os\u0026gt;@\u0026lt;ip\u0026gt; # 루트 권한으로 변경 sudo su # ip 복사 # /mnt 디렉토리 안에 efs 폴더 생성 cd /mnt \u0026amp;\u0026amp; mkdir efs # 복사한 ip 주소 입력 # 확인 df -hT | grep efs AWS S3(Simple Storage Serive) 객체 스토리지 서비스로 데이터를 객체 단위로 저장 객체는 파일 데이터와 메타 데이터로 구성되며 인터넷을 통해 접근 가능 특징 내구성 및 가용성 : S3는 99.99% 내구성 제공 및 여러 가용 영역의 복제되어 높은 가용성 보장 확장성 : 거의 무한대로 확장 가능 보안 : 데이터 암호화 후 저정 및 전송하며 IAM 정책, 버킷 정책, ACL을 통해 엑세서 권한 제어 비용과 효율성 : 저장한 데이터 양과 사용한 리소스에 따라 지용 지불 데이터 관리 기능 : 버전 관리, 수명 주기 정책, 객체 잠금, 이벤트 알림 등 데이터를 효울적으로 관리 사용 예시 중요한 데이터 백업 및 복원에 사용 오랫동안 보관해야 하지만 자주 접근하지 않는 데이터의 아카이빙에 적합 정적 웹 사이트 호스팅에 사용 미디어 콘텐츠 저장 후 배포 시 사용 실습(볼륨 확장) S3 생성(모든 퍼블릭 허용) 권한 추가 파일 업로드 url 클릭 후 확인 AWS Lambda 서버를 프로비저닝하거나 관리할 필요 없이 코드를 실행 할 수 있는 컴퓨팅 서비스 코드를 업로드하고 실행 조건을 설정하면, 나머지 인프라 관리는 AWS에서 자동으로 처리 특징 서버를 프로비저닝, 관리, 확장할 필요가 없이 AWS에서 모든 인프라 관리 Lambda 함수는 요청에 따라 자동 확장 다양한 프로그래밍 언어 지원 사용 예시 파일 업로드 이벤트 발생 시 트리거하여 파일 처리 실시간 데이터 처리 및 로그 분석, 필터링, 알람 트리거 수행 백업, 보고서 생성, 시스템 유지보수 작업 자동화 실습(볼륨 확장) Lambda 생성 코드 수정 테스트 클릭 및 모니터링 로그 확인 트리거 추가 파일 업로드 모니터링 확인 AWS CloudWatch 인프라와 애플리케이션의 상태를 모니터링하고 관리하는 서비스 다양한 AWS 서비스와 통합되어 메트릭 수집, 경보 설정, 로그 모니터링 및 분석 특징 EC2, RDS, S3, DynamoDB 등 다양한 AWS 서비스에서 메트릭 자동 수집 특정 조건 충족 시 알람 생성해 SNS 및 함수 트리거, auto Scaling 조치 대시보드를 사용해 모니터링 시스템 이벤트 감지 및 지정된 대상으로 알림 전송 임계값 초과 시 경보 설정 및 자동 대응 조치 실습(볼륨 확장) IAM 역할 생성(AWSLambdaBasicExecutionRole, CloudWatchEventsFullAccess) lambda 생성 구성 - 권한 - 편집 - 역할 변경 이벤트 브리지 규칙 생성(aws , cloudWatch, Alarm, kakao) cloudWatch 대시보드 - 경보상태 - 경보 생성 지표 선택 - 인스턴스 - cpu - 지표 선택 ","date":"2024-07-17T11:42:15+09:00","permalink":"https://choiseungwoo98.github.io/p/aws-aws%EC%97%90-ebs-lambda%EC%99%80-efs/","title":"[AWS] aws에 EBS, Lambda와 efs"},{"content":" 오늘은 AWS 첫번째 실습 시간이다.\nIAM에 대해 공부 후\nS3를 통해 제어하는 실습\nIAM 클라우드 서비스에서 사용자의 리소스 접근을 제어하는 웹 서비스 사용자 및 그룹을 생성해 리소스 권한 관리 IAM User Aws 리소스에 접근하기 위해 생성되는 개별 엔터티 고유한 자격 증명(로그인 정보)과 함께 제공, 권한을 부여받아 작업 수행 IAM Group 공통적인 권한을 부여하기 위해 사요되는 논리적 단위 사용자별 권한을 할당하는 대신 그룹에 권한 할당 실습 IAM User 생성 IAM User Group 생성 생성한 유저 로그인 후 권한 확인 IAM 정책(Policy) AWS 리소스에 대한 접근 권한을 정의하는 JSON 문서 권한을 세부적으로 제어 보안과 권한 관리를 위해 필수적인 구성 요소 관리형 정책(Managed Policies) 미리 정의된 정책으로 사용자가 쉽게 권한을 부여할 수 있도록 설계\n인라인 정책(Inline Policies) 특정 사용자, 그룹 또는 역할에 직접 연결된 정책\n다른 엔터티와 공유되지 않고 연결된 엔터티 삭제 시 정책도 삭제\n권한을 좀 더 세밀하게 제어하고자 할 때 사용\n구성요소 statement : 정책의 주요 내용이 포함된 부분, 다중 statement 가능 Effect : 권한 효과를 정의(허용 혹은 거부) Action : 허용, 거부할 작업 정의 Resource : 작업이 적용되는 리소스 정의 Condition : 조건을 추가해 세부적인 적용 제어 실습 정책 추가 버킷 생성 권한 정책 연결 후 테스트 IAM 역할(Role) 역할(Role) : 특정 AWS 서비스나 다른 계정의 사용자등이 AWS 리소스에 접근할 수 있도록 임시 보안 자격 증명을 제공 정책(Policy) : 권한을 정의하는 JSON 문서 신뢰정책(Trust Policy) : 역할을 맡을 수 있는 엔터티 정의 정책 역할 전환(Role Assumption) : 역할을 맡는 과정 정책 종류 권한 정책(Permission Policy) : 역할을 맡은 엔터티가 수행할 수 있는 작업 정의 신뢰 정책(Trust Policy) : 어떤 엔터티가 역할을 맡을 수 있는지 정의 사용 방식 AWS 서비스 간의 권한 부여 : EC2 인스턴스가 S3 버킷에 접근 가능하도록 역할 사용 계정 간 권한 부여 : 사용자가 다른 AWS 계정의 리소스에 접근 할 수 있도록 역할 사용 단기 자격 증명 : 임시 자격 증명을 사용해 특정 기간 동안 접근 권한 부여 실습 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 인스턴스 접속 ssh -i \u0026lt;key\u0026gt; \u0026lt;os\u0026gt;@\u0026lt;ip\u0026gt; # aws 설치 확인 asw --version # S3에 파일 업로드 aws s3 cp \u0026lt;파일명\u0026gt; s3://\u0026lt;버킷이름\u0026gt;/ # S3에 업로드된 파일 내려받기 aws s3 cp \u0026lt;파일명\u0026gt; s3://\u0026lt;버킷이름\u0026gt;/\u0026lt;버킷내 파일명\u0026gt; \u0026lt;로컬 파일명\u0026gt; # S3에 업로드된 파일 리스트 aws s3 ls \u0026lt;파일명\u0026gt; s3://\u0026lt;버킷이름\u0026gt;/ # S3에 업로드된 파일 삭제 aws s3 rm \u0026lt;파일명\u0026gt; s3://\u0026lt;버킷이름\u0026gt;/\u0026lt;버킷내 파일명\u0026gt; ","date":"2024-07-15T15:01:46+09:00","permalink":"https://choiseungwoo98.github.io/p/aws-aws-iam%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-s3-%EC%8B%A4%EC%8A%B5/","title":"[AWS] AWS IAM을 이용한 S3 실습"},{"content":" 오늘은 AWS 첫번째 실습 시간이다.\nEC2에서 VPC를 사용하고 public이랑 private를 열어\npublic은 LB를 테스트하고\nprivate은 NAT를 이용한 인터넷 연결을 실습했다.\nCSP(Cloud Service Provider) 클라우드 컴퓨팅 서비스를 제공하는 회사(Ex. AWS, Azure, GCP, NCP 등) 인프라 서비스(IaaS), 플랫폼 서비스(PaaS), 소프트웨어 서비스(SaaS) 제공 AWS(Amazon Web Services) 아마존에서 제공하는 클라우드 컴퓨팅 플랫폼 현재 높은 점유율로 클라우드 시장에서 강세를 보이고 있다. 클라우드 컴퓨팅 내용 온프레미스(On-premise) 환경과 반대의 의미로 많이 사용 IT 인프라를 조직 내부에 직접 설치하고 운영하는 방식 장점 비용 절감 : 필요한 만큼 컴퓨팅 자원과 스토리지 대여를 통해 비용 절감 속도와 민첩성 : 시스템 자체에 대한 확정을지원하는 클라우드 특성상 빠르게 확장을 진행 할 수 있다. 글로벌 서비스 : 특정 지역에 한정되는 온프레미스와 달리 전세계적인 데이터 센터를 통해 사용 탄력성 : 모든 CSP에서는 리소스 사용량 증가로 인한 서비스 장애 방지를 위해 탄력적으로 사용 가능한 리소스 조절 보안 : 네트워크 방화벽, WAF 등을 통해 강력한 보안 유지 AZ(Availability Zone) 내용 하나의 Region 내에 위치한 데이터 센터 그룹 고가용성과 내결함성을 위해 여러 AZ에 걸쳐 앱 배포 Region 지리적으로 분리되어 여러 위치로 구분 리전끼리 통신 시 별도 비용이 추가될 수 있다. 글로벌 서비스 특성상 빠른 서비스를 제공하기 위해 여러 리전에 걸쳐 앱 배포 VPC(Virtual Private Cloud) 내용 개인 네트워크를 구성하는 요소 서브넷, 라우팅 테이블, 보안 그룹, 인터넷 게이트웨이, NAT 게이트웨이 이점 격리성 : 격리된 환경에서 구성하기 때문에 다른 네트워크에 간섭을 받지 않는다. 보안성 : 세부적인 보안 설정 가능 확장성 : 필요에 따라 서브넷 추가 구성, 라우팅 테이블, 보안 그룹 등 쉽게 추가 유연성 : 요구에 따라 온프레미스와 혼합해 하이브리드 클라우드 구성 VPC 요소 서브넷 실제 VM이 올라갈 네트워크 대역을 설정 private와 public은 인터넷 게이트웨이 유무와 라우팅 테이블에 인터넷 게이트웨이 추가 여부 private는 NAT 게이트웨이를 통하지 않는 이상 인터넷 통신 불가 public은 기본적으로 가능 라우팅 테이블 서브넷에서 사용되는 네트워크 네비게이션 같은 존재 CIDR 기반으로 동작, 각각의 대역에 대해 경로 설정 가능 보안 그룹 ACL(Access Control List)처럼 출발 IP, Port에 따라 출입 여부 결정 아웃바운드는 보통 통신의 원활함을 위해 열어두는 편 인바운드는 접속 및 통신용 포트를 제외한 나머지 통제 인터넷 게이트웨이 퍼블릭 서브넷을 결정하는 요소 라우팅 테이블과 조합하여 특정 대역만 인터넷이 가능하도록 설정(대부분 관리 비용이 때문에 다 열어둔다.) NAT(Network Address Translation) 게이트웨어 private에서도 인터넷 사용 가능 모든 경로를 다 열지 않고 특정 포트만 보안 그룹을 통해 연다. AWS EC2(Elastic Cloud Computer) UTM을 통해 VM을 생성하던 것과 비슷한 구조 CPU, Memory, 저장소 용량 등을 미리 정하고 생성 LB(Load Balancer) AWS에서 네트워크 트래픽을 여러 대상으로 분산시켜 가용성과 탄력성을 높이는 서비스 ALB(Application Load Balance) HTTP 및 HTTPS 트래픽에 최적화된 7 단계 로드 밸런서 CloudWatch와 통합되어 다양한 지표와 로그 모니터링 NLB(Network Load Balancer) 고성능을 요구하는 TCP, UDP 및 TLS 트래픽에 최적화된 4계층 로드 밸런서 매우 낮은 지연 시간, 고가용성 CLB(Classic Load Balancer) 구형 로드 밸런서로 4계층 + 7계층 로드 밸런서 설정이 간단하고 직관적 실습 LB 생성 순서\nVPC 생성 서브넷 생성(여러개) 공통 보안 그룹 생성 인터넷 게이트웨이 생성 nat 게이트웨이 생성 인스턴스 생성(여러개) 라우팅 테이블 생성(public, private) LB 생성 타겟 그룹 생성 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # 양쪽 서버에서 똑같이 진행 # 퍼블릭 서버 접속 ssh -i \u0026lt;key 파일 명\u0026gt; \u0026lt;OS 명\u0026gt;@\u0026lt;ip 주소\u0026gt; # 파이썬 실행을 위한 다운로드 sudo apt(yum) update \u0026amp;\u0026amp; sudo apt(yum) install -y python3-flask # 파이썬 파일 작성 vi app.py # 파일 실행 sudo python3 app.py # LB DNS를 활용해 접근 # private 접근 하기 # public 서버에 접근 한 후 tem 파일 복사 후 파일 생성 vi key.tem # private 접속 - 같은 네트워크 대역이라 접속이 가능하다. ssh -i key.tem \u0026lt;OS\u0026gt;@\u0026lt;IPv4\u0026gt; # private 접속 후 apt(yum) update # 인터넷 연결이 없기 때문에 update 되지 않음 sudo apt(yum) update # NAT 연결 후 인터넷 연결 테스트 sudo apt(yum) update ","date":"2024-07-15T15:01:46+09:00","permalink":"https://choiseungwoo98.github.io/p/aws-aws%EC%99%80-lb-%EC%8B%A4%EC%8A%B5/","title":"[AWS] AWS와 LB 실습"},{"content":" 오늘은 주말이라 여태까지 배운 네트워크에 대해\n정리하면서 복습을 진행해보고자 한다.\n다시 기억하기 위해 화이팅!\n네트워크 둘 이상의 컴퓨터와 연결하는 링크의 조합 물리적 네트워크, 논리적 네트워크 형성 물리적 네트워크 : 어댑터, 케이블, 전화선 논리적 네트워크 : 소프트웨어, 개념 모델 OSI 7, 4 Layer OSI(Open System Interconnection : 개방형 시스템 상호 연결) 다양한 통신 시스템이 통신 할 수 있도록 국제 표준화 기구에서 만든 개념 모델\nOSI 7 Layer 응용 프로그램 계층(Application Layer) : 사용자가 사용하는 응용 프로그램과 인터페이스 제공 프레젠테이션 계층(Presentation Layer) : 데이터 형식 변환 밑 표준화 데이터 형식 변환 : 컴퓨터 시스템 간 데이터 송수신 시 공통된 형식으로 변환(Ex. 이미자나 동영상 같은 파일을 보낼 때 컴퓨터가 이해할 수 있도록 변환) 데이터 암호화 : 데이터를 안전하게 전송하기 위해 암호화 진행(Ex. 애플리케이션 내 암호화(PDF, Word 등), 파일 암호화(Zip 압축 시 암호 설정)) 데이터 압축 : 데이터의 효율적인 전송을 위해 압축 세션 계층(Session Layer) : 두 컴퓨터 간의 통신이 원할하기 위한 설정, 유지, 관리를 도와주며 동기화를 보장하기 때문에 효율성과 안정성이 보장된다. 동기화 : 데이터 전송 중 오류가 발생하거나 중단된 경우 재시작 할 수 있는 지점 설정 전송 계층(Transport Layer) : 데이터를 신뢰성 있게 전송, 속도 조절, 데이터가 손실되지 않도록 하는 중요한 역할 데이터 분할 및 재조립 : 큰 데이터 전송 시 작은 조각으로 나눈 후 수신자가 복원 데이터 전송의 신뢰성 : 데이터가 손실되거나 손상되지 않고 정확히 도착했는지 확인 흐름 제어 : 데이터를 너무 빠르게 보내서 수신자가 처리하지 못하는 상황을 방지하기 위해 속도 조절 혼잡 제어 : 네트워크 혼잡 시 데이터 전송 속도를 조절해 혼잡을 줄인다. TCP : 신뢰성 있는 전송 보장(Ex. 웹페이지 로드, 이메일 전송 등), UDP : 빠른 데이터 전송 시 사용(Ex. 실시간 스트리밍, 게임 등) 네트워크 계층(Network Layer) : 데이터를 가장 효율적으로 전달, 패킷(데이터 조각)을 주고 받으며 라우팅을 담당 라우팅(Routing) : 데이터가 전송될 때 최적의 경로를 찾는 과정 데이터 링크 계층(Data Link Layer) : 네트워크 장비간에 데이터 송수신 과정에 데이터 오류를 검출하고 수정하는 역할, 물리적 네트워크(이더넷, Wi-Fi)를 통해 올바르게 전달 될 수 있도록 함 물리 계층(Physical Layer) : 실제 물리적인 매체를 통해 데이터가 전기적 혹은 광신호 형태로 전송되는 과정을 담당 물리적 연결 : 케이블, 스위치, 허브 등의 물리적인 장비 연결 전송 매체 : 구리선 케이블, 광섬유, 무선 주파수 등 OSI 4 Layer 단계가 많고 복잡한 구조를 갖고 있어 인터넷 서비스에 적합안 4계층 모델이 나왔다. 응용 계층(Application Layer) : 사용자와 직접 상호작용 하는 애플리케이션 서비스 제공 전송 계층(Transport Layer) :데이터 전송의 신뢰성과 순서 보장(TCP, UDP Protocol) 인터넷 계층(Internet Layer) : 데이터를 패킷 단위로 나누고 목적지 IP 주소를 통해 경로 결정 후 전달 네트워크 인터페이스 계층(Network Interface Layer) : 물리적 네트워크 연결 및 데이터 전송 담당 계층별 장비 리피터(Repeater) 물리 계층 신호를 멀리 보내기 위한 증폭 장치 신호 감쇠 방지 및 전송 거리 증가 허브(Hub) 데이터 링크 계층 여러 장치를 하나의 네트워크로 연결시켜주는 장치 여러 컴퓨터 연결하지만 데이터 충돌 가능성이 있으며 Mac 주소를 인식하지 못한다. 브리지(Bridge) 데이터 링크 계층 두 개의 세그먼트를 연결 및 Mac 주소를 사용해 데이터 프레임 필터링 세그먼트 간의 트래픽 필터링 및 브로드캐스트 도메인 분할하려 충돌 감소 스위치 데이터 링크 계층 여러 장치를 연결하고 Mac 주소를 사용하여 프레임을 특정 포트로 전송 각 포트에 연결된 장치간 통신을 효율적으로 관리 및 충돌 도메인 분리해 성능 향상 라우터 네트워크 계층 다른 네트워크 간 데이터 전송, IP주소를 사용해 경로 결정 여러 네트워크를 연결해 데이터 패킷을 올바른 경로로 라우팅, 논리적 주소(IP 주소)를 기반으로 네트워크 트래픽 관리 HTTPs와 SSL, TLS HTTPs(Hypertext Transfer Protocol Over Secure Socket Layer) HTTP는 암호화 없이 데이터를 전송하기 때문에 보안이 취약해 보안하기 위해 탄생\nSSL(Secure Sockets Layer) 인터넷 통신의 보안을 강화하기 위해 사용되는 암호화 프로토콜로 서버간 전송되는 데이트를 암호화해 제 3자가 도청 및 변조하지 못하도록 한 것\nHTTP가 SSL을 사용해 HTTPs가 되었다.\nTLS(Transport Layer Security) SSL의 후속 버전으로 인터넷 통신의 보안을 강화하기 위해 사용되는 암호화 프로토콜(사실상 SSL이랑 같음)\n네트워크 용어 정리 LAN(근거리 통신망) : 허브, 스위치로 연결하는 소큐모 네트워크, 주로 컴퓨터 장치와 연결된 네트워크를 말한다. MAN(대도시 통신망) : 도시와 도시의 통신망을 뜻하며 2개 이상의 LAN을 라우터, 브릿지로 연결, 고속 데이터 전송을 지원하며 통신사나 공공기관에서 운영한다. WAN(국가간 통신망) : 광역 네트워크로 지리적으로 넓은 영역에 걸쳐 여러 LAN, MAN을 연결하는 네트워크, 주로 Internet이라고 한다. WLAN(무선 근거리 통신망) : 라디오, 마이크로파(무선 랜 카드 등)를 이용해 데이터를 전송 VPN(사설 통신망) : 가상 사설망으로 공중 네트워크를 암호화된 방법으로 접속할 수 있는 기술 VPC : 퍼블릭 클라우드 환경에서 사용할 수 있는 고객 전용 사설 네트워크 NAT : Private IP 주소로 외부와 통신할 수 없어 Public IP 주소로 변환(Ex : 공유기) IP : 네트워크 상의 장치들을 식별하는 고유한 주소 Ethernet : 컴퓨터나 다른 장치들이 데이터를 물리적으로 주고 받을 수 있도록 연결하는 방식 서브넷 : 큰 네트워크를 작은 네트워크로 나누는 것 서브넷팅 : 네트워크를 서브넷으로 나누는 과정 서브넷마스크 : IP 주소를 서브넷으로 나누기 위한 도구 라우터 : 둘 이상의 패킷 전환 네트워크 또는 서브네트워크를 연결하는 장치, 네트워크 계층에서 동작한다. 라우팅 : 다양한 네트워크 간에 데이터를 전송하는 역할, 네트워크에서 패킷을 받아 목적지까지 최적의 경로를 결정 후 데이터 전달 패킷 : 네트워크에서 출발지와 목적지간에 라우팅되는 데이터 단위 포트 : 소프트웨어 기반이며 OS에서 관리하는 네트워크 연결이 시작되고 끝나는 가상의 지점 프로토콜 : 데이터 교환 방식을 정의하는 규칙 체계 CIDR : 데이터 라우팅 효율성을 향상시키는 IP주소 할당 방법 루프백 : localhost로 알려져 있으며 자신의 ip 스택을 통해 네트워크 인터페이스로 전송된 데이터를 동일한 시스템으로 다시 전송 멀티캐스트 : 하나의 송신자가 여러 수신자에게 동시에 데이터를 전송하는 방식 주로 스트리밍, 주식 거래 등 대규모 수신자에게 동일한 데이터를 효율적으로 전달해야 하는 경우 포트포워딩 : 외부 네트워크에서 특정 포트로 들어오는 트래필을 내부 네트워크의 특정 IP 주소와 포트로 전달하는 네트워크 설정 보수표현법 : 컴퓨터에서 음수를 표현하는 데 사용하는 방법, 1의 보수는 반전(1010 -\u0026gt; 0101), 2의 보수는 반전 후 1을 더함(1010 -\u0026gt; 0110) ","date":"2024-07-13T22:42:04+09:00","permalink":"https://choiseungwoo98.github.io/p/network-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%B3%B5%EC%8A%B5/","title":"[Network] 네트워크 복습"},{"content":" 오늘은 주말이라 강좌로 올라와있는\n네트워크 개념 잡기를 수강하고 정리하고자 한다.\n도메인 IP는 숫자로만 이루어져 기억하기 어렵기 때문에 이름을 부여한 것\nIP 인터넷에 연결되어 있는 장치(컴퓨터, 스마트폰 등)을 식별할 수 있는 주소(Ex. 172.217.161.206)\n웹사이트 ip 주소 가져오는 방법 : nslookup google.com\n네임 스페이스 도메인 이름을 계층적으로 구성하여 네트워크 상의 자원을 고유하게 식별 및 관리\n포트포워딩 외부 네트워크에서 특정 포트를 통해 들어오는 트래픽을 내부 네트워크의 특정 장치나 포트로 전달하는 네트워크 설정\nHTTPs, SSL HTTPs(Hypertext Transfer Protocol Over Secure Socket Layer) HTTP는 암호화되지 않은 방법으로 데이터를 전송하기 때문에 보안이 매우 취약하다. 이것을 보안하기 위해 탄생한 것 HTTP : HTML을 전송하기 위한 통신 규약 Hypertext : 문서와 문서가 링크로 연결 체계 HTTPs : 보안이 강화된 HTTP SSL(Secure Sockets Layer) 인터넷 통신의 보안을 강화하기 위해 사용되는 암호화 프로토콜로 서버간 전송되는 데이트를 암호화해 제 3자가 도청 및 변조하지 못하도록 한 것\nHTTP가 SSL을 사용해 HTTPs가 되었다.\nTLS(Transport Layer Security) SSL의 후속 버전으로 인터넷 통신의 보안을 강화하기 위해 사용되는 암호화 프로토콜(사실상 SSL이랑 같음)\nHTTPs, SSL 디지털 인증서 대칭키 암복호화에 동일한 키를 사용하는 방식으로 송수신자자가 동일한 키를 공유해 통신의 기밀성을 유지한다.\n대칭키를 수신자에게 전송할 때 대칭키가 유출될 수도 있는 치명적인 단점이 있다.\n공개키 비대칭 암호화 방식 중 한 종류로 두 개의 키(공개키, 비밀키)를 사용해 데이터 암복호화 수행\n공개키로 암호화 후 전송하면 수신자는 비밀키로 복호화한다.\n반대로 비밀키로 암호화 하면 공개키로 복호화를 해야하는데 이것은 공개키를 갖고 있는 사람 모두가 복호화 할 수 있어 암호화에 의미가 없지만\n비밀키를 갖고 있는 사람이 암호화 했다는 것을 검증하는 것이라 신원을 확인 할 수 있다.\nSSL 통신 과정 악수(Handshake) : 클라이언트와 서버가 안전한 통신을 설정하기 위해 필요한 매개변수를 협상하는 과정 클라이언트 헬로 : 클라이언트가 서버 접속을 시도하고 메시지를 보낸다.(SSL/TLS 버전, 암호화 방식 등) 서버 헬로 : 메시지 수신 및 응답(SSL/TLS 버전, 암호화 방식 등) 서버 인증 및 키 교환 : 서버가 클라이언트에게 인증서를 보낸다.(CA에서 발급된 공개키를 포함, 메시지도 보낼 수 있다.) 클라이언트 인증 및 키 교환 : 서버 인증서 검증, 프리마스터 시크릿을 생성하고 서버 공개키를 암호화하여 서버로 보낸다. 프리마스터 시크릿 : 세션 키 생성 : 자신의 무작위 데이터와 프리마스터 시크릿을 사용한 동일한 세션키 생성 암호화 통신 시작 : 클라이 언트는 핸드셰이크 완료라는 메시지를 보내고 서버는 핸드셰이크 완료 메시지로 응답(메시지는 세션키로 암호화 된다.) 데이터 전송(Data Transfer) : 클리이언트와 서버는 세션 키를 사용하여 데이터를 암호화하여 안전하게 주고 받을 수 있다. 세션 종료(Session Termination) : 통신이 끝나면 클라이언트와 서버는 SSL 연결 종료 종료 요청 : 클라이언트 또는 서버가 연결을 종료하고자 하면 종료 요청 메시지를 보낸다.(메시지는 세션키로 암호화 된다.) 연결 종료 : 연결을 정상적으로 종료 후 사용된 세션 키와 관련 데이터 폐기 ","date":"2024-07-13T16:42:04+09:00","permalink":"https://choiseungwoo98.github.io/p/network-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EB%8F%84%EB%A9%94%EC%9D%B8-https/","title":"[Network] 네트워크 도메인, HTTPs"},{"content":" 오늘은 실습보다 이론위주의 수업이었다.\n도커 보안에 대해 간단하게 설명하고 들었던 것들을 정리하고자 한다.\nDocker Security Rootless Mode 개념 Docker를 실행할 때 관리자 권한 없이 실행시키는 모드 특징 시스템 전체에 대한 권한 없이 사용할 수 있어 잠재적 보안 위험을 낮출 수 있다. 모두 일반 사용자 권한으로 시스템 자원에 대한 접근 제한 Linux Capabilities 개념 리눅스 커널에서 제공하는 기능으로 시스템 관리 권한을 세분화하여 특정 작업에 대해 권한을 부여할 수 있다. 특징 컨테이너 생성 시 필요한 권한만 부여해 보안성 향상 Privileged : 컨테이너가 호스트 시스템의 모든 권한을 갖고 있음.(보안 취약) Share Namespace 개념 리눅스 커널의 기능으로 프로세스와 자원(PID, 네트워크, IPC 등)을 격리 시킬 수 있다. 특징 Docker에서는 컨테이너 마다 별도의 네임스페이스를 할당해 다른 컨테이너나 호스트와 격리한다. PID Namespace : 호스트의 프로세스를 볼 수 있음, 프로세스 ID를 격리하여 각 컨테이너가 다른 프로세스를 보지 못하게 한다. IPC Namespace : 호스트의 , 인터이페스 통신을 격리한다. Network Namespace : 호스트의 , 네트워크 인터페이스를 격리해 컨테이너 간 네트워크 충돌을 방지한다. 추가적인 내용 리눅스 심화 Security Layer 개념 리눅스 커널에서 제공하는 보안 메커니즘으로 Docker 이미지에서 보안 패치를 적용한 레이어이다. 시스템 호출 제어와 프로그램 동작 제한을 통해 보안을 강화하는데 사용 특징 Docker 이미지는 여러 레이어로 구성되며, 취약점 발견 시 해당 레이어만 업데이트 해 보안성 유지 이미지 전체를 다시 빌드할 필요 없이 특정 레이어만 업데이트 할 수 있어 효율적이다. AppArmor : 리눅스 커널에서 제공하는 보안 모듈로 애플리케이션 접근할 수 있는 자원을 제어(강제적 접근 제한 chmod, chown, setuid 등보다 더 로우한 거) Seccomp : 리눅스 커널에서 제공하는 보안 기능으로 시스템 콜을 필터링해 애플리케이션을 실행할 수 있는 시스템 콜 제한 Privileged Container와 UnPrivileged Container Privileged Container 컨테이너는 Host에서 독립된 namespace 영역을 가지고 있어 시스템의 주요자원에 접근할 수 있는 권한이 없음 Privileged 옵션으로 Container를 생성하면 Host의 리눅스 커널 기능을 모두 사용할 수 있고 모든 Host 주요 자원에 접근할 수 있음 UnPrivileged Container 시스템 주요 자원에 접근할 수 있는 권한이 부족해 네트워크 인터페이스 활성화/비활성화나 IP주소의 변경 불가능 Capabilities 모든 권한을 열어주게 되면, 보안적으로 위험할 수 있어 세분화하여 권한을 관리 CAP_NET_ADMIN : 네트워크설정변경 CAP_SYS_ADMIN : 시스템관리작업 CAP_SYS_PTRACE : 다른프로세스추적 Reverse Shell 개념 공격자가 타겟 시스템에 접속하여 원격으로 명령을 실행할 수 있도록 하는 공격 기법 중 하나 외부에서 내부로 접속을 가능하게 해 방화벽을 우회하는 데 사용 작동 원리 공격자 준비 : 자신의 시스템에서 특정 포트를 열어 리스닝 상태로 대기(공격자 시스템) 타겟 시스템 접속 : 타겟 시스템에 악성 코드 또는 스크립트를 실행시켜, 시스템으로 연결(타겟 시스템에서 공격 시스템 연결) 연결 수립 : 연결을 통해 타겟 시스템에서 명령을 실행할 수 있는 쉘에 접근 명령 실행 : 공격자가 타겟 시스템에서 원하는 명령을 실행 방어 방법 방화벽 설정 강화 : 내부에서 외부로의 불필요한 연결 제한, 중요한 시스템에서는 허용된 IP와 포트만 외부로 연결 설정 네트워크 모니터링 : 이상한 네트워크 트래픽을 감지하기 위해 네트워크 트래픽을 지속적으로 모니터링 IDS/IPS 사용 : 침입 탐지 시스템(IDS)이나 침입 방지 시스템(IPS)을 사용하여 의심스러운 활동을 실시간으로 탐지 및 차단합니다. 보안 패치 적용 : 시스템과 애플리케이션의 보안 패치를 최신 상태로 유지하여 악성 코드가 실행될 수 있는 취약점을 최소화합니다. 사용자 교육 : 소셜 엔지니어링 공격을 통해 리버스 셸이 설치될 수 있으므로, 사용자에게 피싱 이메일과 같은 공격 방법에 대한 교육 실시 Linux root 디렉토리 정보 /proc : 시스템 상태, 하드웨어 정보, 프로세스 정보 등이 포함\n/proc/cpuinfo : CPU 정보 /proc/meminfo : 메모리 상태 /etc : 시스템 및 애플리케이션의 설정 파일들이 저장\n/etc/passwd : 사용자 계정 정보 /etc/fstab : 파일 시스템 마운트 정보 /etc/hosts : 호스트명과 IP 매핑 정보 /bin : 시스템 부팅과 기본 운영에 필요한 실행 파일들이 저장\nls, cp, mv, rm 등의 명령어 위치 /sbin : 시스템 관리와 관련된 명령어들이 위치\nreboot, ifconfig, iptables 등의 명령어가 포함 /usr : 사용자 애플리케이션, 라이브러리, 헤더 파일 저장\n/usr/bin : 일반 사용자 명령어 /usr/sbin : 시스템 관리자 명령어 위치 /usr/lib : 라이브러리 파일 포함 /var : 로그 파일, 스풀 디렉토리, 캐시 파일 등이 포함\n/var/log : 로그 파일 /var/spool : 프린터와 메일 스풀 파일들이 저장 /home : 각 사용자별 개인 파일과 설정 파일 저장\n사용자 user1의 홈 디렉토리는 /home/user1 /tmp : 시스템 사용 중 임시로 생성되는 파일들이 위치, 시스템 재부팅 시 대부분의 파일이 삭제됨.\n/dev : 시스템 하드웨어와의 인터페이스를 제공하는 파일들이 포함\n/dev/sda1 : 첫 번째 하드 디스크의 첫 번째 파티션을 나타냄 /lib : 커널 모듈과 공유 라이브러리 파일들이 포함\n/lib/modules : 커널 모듈 위치 ","date":"2024-07-12T14:25:27+09:00","permalink":"https://choiseungwoo98.github.io/p/docker-docker-%EC%9D%B4%EB%A1%A0/","title":"[Docker] Docker 이론"},{"content":" 오늘은 docker compose에 대해 배웠습니다.\n이론이 많지는 않았지만\n앞으로 자주 사용할 것이란 생각이 들어 실습까지 다시 진행하며 복습하겠습니다.\nDocker compose 개념 여러 Docker Continer를 정의하고 실행할 수 있도록 도와주는 도구 docker-compose.yaml 파일을 사용해 서비스, 네트워크, 볼륨 등을 정의 기능 멀티 컨테이너 애플리케이션 정의 : docker-compose-yaml 파일을 통해 여러 컨테이너 정의 서비스 간 의존성 관리 : 여러 컨테이너 간의 의존성을 정의하고, 필요한 순서에 따라 컨테이너 시작 일관된 개발 환경 제공 : 동일한 docker-compose.yaml 파일을 사용해 로컬 개발환경과 프로덕션 환경을 일관되게 설정 간편한 실행 및 종료 : docker compose up / down을 사용해 한번에 시작 및 종료 가능 기능 설명 build context : Dockerfile이 있는 디렉토리 지정 dockerfile : Dockerfile 경로 지정 image : 기존에 존재하는 이미지를 사용할 때 사용할 이미지 지정 ports : 호스트와 컨테이너 간의 포트 매핑 지정 environment : 컨테이너 내에서 사용할 환경 변수 지정 volumes : 호스트와 컨테이너 간의 파일 시스템 마운트를 지정 depends_on : 컨테이너 간의 의존성 지정(Ex : db 서비스 시작 후 web 서비스 시작) networks : 서비스가 연결될 네트워크 지정 restart : 컨테이너 재시작 정책 (전역)volumes : 네트워크 정의, 서비스에서 네트워크 사용 전 전역에 정의 (전역)networks : 서비스에서 네트워크 사용 전 전역에 정의 실습 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 이미지를 내려받는다 docker pull \u0026lt;이미지명\u0026gt; # Docker 이미지를 백그라운드에 무한히 실행되는 컨테이너 시작 docker run -d \u0026lt;이미지명\u0026gt; sleep infinity # 실행한 이미지 접속 docker exec \u0026lt;컨테이너명\u0026gt; /bin/bash # Docker 내부 파일 로컬에 복사 docker cp \u0026lt;컨테이너명\u0026gt;:/\u0026lt;복사할 파일명\u0026gt; \u0026lt;복사할 위치\u0026gt; # Docker compose를 백그라운드로 실행 docker compose -f \u0026lt;실행할 yaml명\u0026gt; up -d # 현재 디렉토리의 Docker-compose.yaml로 정의된 모든 컨테이너 표시 docker compose ps -a # Docker compose 종료 docker compose down ","date":"2024-07-11T13:13:32+09:00","permalink":"https://choiseungwoo98.github.io/p/docker-docker-compose%EC%97%90-%EB%8C%80%ED%95%B4/","title":"[Docker] Docker Compose에 대해"},{"content":" 어제는 도커의 개념과 동작 방식에 대해 정리하였습니다.\n오늘은 docker를 실질적으로 사용해보면서 필요한 내용을 정리해보고자 합니다.\nDockerfile 개념 이미지 생성 목적으로 작성되는 파일\n특징 환경 일관성 : 개발, 테스트, 운영 등 모든 환경에서 동일한 설정 유지 이식성 : 다양한 운영체제에서 동일하게 동작 자동화 : CI/CD 파이프라인 과정에서 빌드 및 배포 과정 자동화 반복 가능성 : 동일한 방식으로 이미지를 빌드해 반복 가능한 환경 제공 확장성 : 마이크로 아키텍처를 이용해 쉽게 확장 지시자 Dockerfile 만들기 이미지 크기 최적화 멀티 스테이지 빌드 사용 : 불필요한 빌드 종속성 제거 불필요한 파일 제외 : .dockerignore을 사용해 빌드에 포함되지 않아도 되는 파일 제외 불필요한 패키지 설치 X 1 2 3 4 5 6 7 FROM golang:1.16 as builder WORKDIR /app COPY . . RUN go build -o myapp FROM alpine-latest WORKDIR /app COPY --from=builder /app/myapp . CMD [\u0026#34;./myapp\u0026#34;] 레이어 캐싱 활용 변경이 적은 레이어 위에 변경이 잦은 레이어 위치 : 자주 변경되는 파일보다 덜 변경되는 파일을 추가해 빌드 캐시 최대한 활용 OverayFS(Upperdir, Lowerdir, Workdir, Merged) 1 2 COPY package*.json ./ RUN npm install COPY . . 보안 고려 최소 권한 원칙 : 루트 권한이 아닌 사용자로 애플리케이션 실행 최신 베이스 이미지 사용 : 보안 패치가 적용된 상태 유지 비밀 정보 제외 : 환경 변수나 소스 코드에 비밀 정보가 포함되지 않도록 주의 성능 최적화 적절한 베이스 이미지 선택 : 필요에 맞는 가장 작은 베이스 이미지 선택 의존성 최소화 : 필요한 라이브러리, 도구만 설치 유지 관리 용이성 명확하고 일관된 Dockerfile 작성 : 주석 추가 및 지사자의 목적을 설명하고 일관된 코드 스타일 유지 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 베이스 이미지 설정 FROM node:14 # 작업 디렉토리 설정 WORKDIR /app # 의존성 설치 COPY package*.json ./ RUN npm install # 애플리케이션 소스 코드 복사 COPY . . # 컨테이너 시작 명령어 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] 유지 관리 용이성 명확하고 일관된 Dockerfile 작성 : 주석 추가 및 지사자의 목적을 설명하고 일관된 코드 스타일 유지 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # 베이스 이미지 설정 FROM node:14 # 작업 디렉토리 설정 WORKDIR /app # 의존성 설치 COPY package*.json ./ RUN npm install # 애플리케이션 소스 코드 복사 COPY . . # 컨테이너 시작 명령어 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] 환경 변수 사용 ENV 지시자나 ARG 지시자를 사용해 환경 변수 설정 ARG Docker build 시간에 사용되는 변수로 빌드 할 때만 유효하며 컨테이너가 실행될 때는 사용 불가 사용방법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 FROM alpine ARG MY_ARG RUN echo \u0026#34;Build-time argument: $MY_ARG\u0026#34; ENV MY_ENV=$MY_ARG ARG DEFAULT_ARG=default_value RUN echo \u0026#34;Default argument: $DEFAULT_ARG\u0026#34; ```shell docker build --build-arg MY_ARG=my_value -t my_image . # 빌드할 때 MY_ARG의 값을 넘겨준다. docker build --build-arg MY_ARG=my_value -t my_image . ENV : 컨테이너 실행 시간에 사용할 환경 변수 사용방법 1 2 3 4 5 6 7 8 9 10 # ENV 사용 예시 FROM alpine ENV MY_ENV=my_value RUN echo \u0026#34;Environment variable: $MY_ENV\u0026#34; ENV MY_ENV=another_value RUN echo \u0026#34;Overridden environment variable: $MY_ENV\u0026#34; 1 docker run -e MY_ENV=runtime_value my_image Dorkerfile DeepDive Multi-Stage Build Dockerfile 작성 시 여러 단계를 사용해 이미지를 빌드하는 기법 빌드에만 필요한 툴, 라이브러리 또는 불필요한 파일, 도구는 최종 이미지에서 제거해 보안 강화 및 크기 감소 효과 여러 단계로 빌드를 나누어 관리 용이 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # Go 언어 이미지를 기반으로 설정 (golang:1.16) FROM golang:1.16 AS builder # 작업 디렉토리 설정 (/app). WORKDIR /app # 소스 코드 복사. COPY . . # 애플리케이션 빌드 (go build). RUN go build -o myapp . # 경량의 Alpine Linux 이미지를 기반으로 설정 FROM alpine:latest # 작업 디렉토리 설정 (/app). WORKDIR /app # builder 스테이지에서 빌드된 애플리케이션 복사. COPY --from=builder /app/myapp . # Expose port 8080 EXPOSE 8080 # 애플리케이션 실행 (CMD [\u0026#34;./myapp\u0026#34;]). CMD [\u0026#34;./myapp\u0026#34;] Layer Caching 이전에 빌드된 레이어를 캐시하여 빌드 속도 향상시키는 기술 각 레이어가 해시를 사용해 동일한 명령어와 결과를 생성하면 이전에 빌드된 레이어 재사용 Dockerfile에 명령어가 변경되면 그 이후 모든 레이어 다시 빌드 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # Node.js 이미지를 기반으로 설정. FROM node:14 # package.json 파일을 복사. 이 레이어는 종속성을 설치하는 데 사용됩니다. COPY package.json /app/ # 작업 디렉토리 설정 (/app). WORKDIR /app # 종속성을 설치. package.json이 변경되지 않으면 이 레이어는 캐시됩니다. RUN npm install # 나머지 소스 코드를 복사. 이 명령어가 변경되면 이후 레이어는 다시 빌드됩니다. COPY . /app # 애플리케이션을 빌드. RUN npm run build # 애플리케이션 시작 CMD [\u0026#34;npm\u0026#34;, \u0026#34;start\u0026#34;] 최적화 이전에 작성해 놓은 부분 참고 Docker 개론\nDocker 저장소 Docker Hub 이미지 호스팅 서비스 : 개인이 이미지를 만들어 배포 가능, 공식 저장소의 소프트웨어 포함 Docker Local Registry : 로컬 환경에서 관리 및 사용 가능 오늘의 실습 dockerfile을 통해 이미지를 만들고 Docker Hub에 repository 생성하기 및 내려받기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 # 테스트 폴더 생성 mkdir dockerfile-test # Dockerfile 파일, 간단한 테스트용 Python 파일, 필요한 패키지와 버전을 명시하는 requirements 파일 생성 touch Dockerfile app.py requirements.txt # 파일 내용 수정(상황에 맞게 작성) cat Dockerfile # Docker 로그인 docker login # 이미지 빌드 docker -f Dockerfile -t \u0026lt;user-name\u0026gt;/\u0026lt;repo-name\u0026gt; . # 내 레포지토리에 이미지 생성 docker push \u0026lt;user-name\u0026gt;/\u0026lt;repo-name\u0026gt; # 실행 및 컨테이너 접속 docker run -it \u0026lt;Container\u0026gt; /bin/bash # Docker 객체에 대한 자세한 정보 출력 docker inspect \u0026lt;Container_id or name\u0026gt; # 이미지 실행 반복적으로 docker run -d \u0026lt;image\u0026gt; sleep infinity # 실행되고 있는 컨테이너의 모든 아이디 값 가져오기 docker ps -q # 실행되고 있는 컨테이너 전체 종료 docker stop $(docker ps -q) # 생성한 레포지토리에서 이미지 내려받기 docker pull \u0026lt;user-name\u0026gt;/\u0026lt;repo-name\u0026gt; ","date":"2024-07-10T16:16:44+09:00","permalink":"https://choiseungwoo98.github.io/p/docker-dockerfile-%EA%B8%B0%EC%B4%88/","title":"[Docker] Dockerfile 기초"},{"content":" 기존에 혼자 Docker에 대해 잠깐 공부한 적 있지만 심도있게 다루지는 않았습니다.\n카카오 테크 부트캠프를 시작하면서 클라우드 수업을 듣기 시작했고\ndocker는 매우 중요한 부분이라 생각해 다시 정리하면서 복습하고자 합니다.\nDocker 개념 컨테이너 기반의 오픈소스 가상화 플랫폼으로 애플리케이션을 소프트웨어의 실행 환경과 함께 패키징해 손쉽게 배포, 실행 할 수 있도록 도와준다.\n주요 개념 Image : 애플리케이션과 필요한 모든 종속성(라이브러리, 설정 파일 등)을 포함하는 읽기 전용 템플릿, 컨테이너를 만드는데 사용 Container : 이미지를 실행한 상태로 격리된 애플리케이션 실행 환경 제공, 독립적으로 실행되며 호스트 시스템 리소스 공유 Dockerfile : 이미지 정의하는 설정 파일, 이미지를 빌드하는데 필요한 명령어 포함 DockerHub : Docker 이미지 중앙 저장소로 공개 또는 개인 저장소로 사용 가능 동작 방식 Docker Daemon : Docker에 핵심 프로세스로 컨테이너 생성 및 관리 Client : 사용자와 데몬 간의 인터페이스 역할 수행 이미지 생성 : Dockerfile을 이용해 이미지 생성, 각 명령어는 새로운 레이어 생성 컨테이너 실행 : 이미지를 사용해 컨테이너 실행, 이미지의 읽기 전용 레이어 위에 쓰기 가능한 레이어 추가 최적화 방법 다단계 빌드 사용 : 여러 단계에 걸쳐 빌드해 중간 산출물을 제거를 통해 불필요한 빌드 단계와 종속성을 제거하여 경량화 캐시 활용 : Dockerfile 명령어 순서를 최적화하여 빌드 속도 개선 불필요한 파일 제거 : 이미지에 포함되지 않아도 되는 파일을 .dockerignore 파일에 추가해 경량화 경량 베이스 이미지 사용 : alpine과 같은 이미지 사용 컨테이너 리소스 제한 : CPU와 메모리를 제한하여 시스템 리소스를 효율적으로 사용 Container 개념 애플리케이션과 그 애플리케이션이 실행되는 환경을 패키징하는 가벼운, 독립적인 실행 환경이다. 가상머신과 비슷하지만 훨씬 가볍고 빠르다. 운영체제 수준에서 CPU, 메모리, 스토리지, 네트워크 등 리소스를 쉽게 공유하고 별도의 실행 환경을 제공한다. 주요 특징 경량성 : 호스트 운영 체제의 커널을 공유하기 때문에 가상머신보다 가볍고 빠른 실행이 가능하다. 이식성 : 어디서나 동일하게 실행된다. 격리성 : 컨테이너는 서로 독립적으로 실행된다. 각 컨테이너는 자체 파일 시스템, 네트워크, 프로세스 공간 소유 동작 원리 Docker 컨테이너는 Docker 이미지로 부터 생성되며 이미지는 컨테이너를 실행하기 위한 모든 파일과 설정이 포함된 불변 템플릿이다.\n가상머신(Virtual Machine) vs Docker Docker 탄생 배경 전통적인 배포 방식 소프트웨어 개발과 배포 과정에서 발생하는 다양한 문제점을 해결하기 위해 등장했다.\n환경 불일치 : 개발 환경과 운영 환경이 서로 다르다면 정상 작동하지 않을 수 있다. 복잡한 설정 : 배포 시 수 많은 설정들을 하나하나 설정 하다보면 실수를 발생시킬수 있고 시간이 오래걸린다. 리소스 낭비 : 각 애플리케이션 마다 별도의 운영 체제를 실행하고 이는 CPU와 메모리 같은 자원을 많이 소비한다. 도커 일관된 환경 제공 : 개발, 테스트, 배포 환경을 모두 동일하게 만들어 준다. 간편한 설정 : 애플리케이션이 실행되는 환경을 코드로 정의 리소스 효율성 : 호스트 운영 체제의 커널을 공유해 가볍고 빠르다. Docker 명령어 정리 run: 이미지에서 새로운 컨테이너 생성 및 실행 exec: 실행 중인 컨테이너 내에서 명령어 실행 ps: 현재 실행 중인 컨테이너 목록 표시 build: Dockerfile을 기반으로 이미지 빌드 pull: 레지스트리에서 이미지 다운로드 push: 이미지를 레지스트리에 업로드 images: 로컬에 저장된 이미지 목록 표시 login: 레지스트리에 로그인 logout: 레지스트리에서 로그아웃 search: Docker Hub에서 이미지 검색 version: Docker 버전 정보 표시 info: 시스템 전체 정보 표시 ","date":"2024-07-09T22:16:44+09:00","permalink":"https://choiseungwoo98.github.io/p/docker-docker-%EA%B8%B0%EC%B4%88/","title":"[Docker] Docker 기초"},{"content":" 리눅스에 대해 배웠다.\n오늘은 실습이 주를 이뤘다. 각각의 명령어가 무슨 일을 하는지 모르다 보니 사실상 한컴타자연습 느낌.. 이렇구나 하고 넘어가는 정도라 다시 정리\u0026hellip;!\nCGroup(Control Group) 개념 프로세서가 사용하는 자원(CPU, 메모리, 디스크, I/O, 네트워크 대역폭 등) 관리 및 제한 애플리케이션의 성능 최적화 및 제어 프로세스를 그룹으로 묶고 사용할 수 있는 자원을 제한, 제어하는 방식 주요 기능 리소스 제한 : 자원을 제한해 안정성 보장 리소스 우선순위 : 중요도에 따른 자원을 할당 및 제한 리소스 계정 : 그룹 별 자원 사용량 모니터링 및 통계 정보 제공 리소스 격리 : 다른 프로세서 그룹 간의 자원 사용을 격리하여 타 그룹에 영향이 미치지 않도록 함 구조 cpu : 사용량 제한 및 보장 cpuacct : 사용량 모니터링 memory : 사용량 제한 및 통계 제공 blkio : 블록(디스크) I/O 사용량 제한 및 모니터링 net_cls : 네트워크 트래픽 분류 및 제한 freezer: 프로세스 중단, 재개 devices: 장치 접근 제어 hugetlb: 큰 페이지 메모리 사용량 제한 perf_event: 성능 이벤트 모니터링 사용법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # cgroup 실습 환경 세팅 sudo apt-get install cgroup-tools-stress # cpu 제한 실습 # cpulimit이라는 이름으로 cgroup 생성 sudo cgcreate -g cpu:/cpulimit # 생성 여부 확인 lscgroup | grep cpulimit # cpu 제한 설정(50000을 출력 후 출력 값을 cpu.max 파일에 기록) echo 50000 | sudo tee /sys/fs/cgroup/cpulimit/cpu.max # cpu 실행(cgroup의 cpu 서브시스템을 사용하는데 stress 도구를 사용해 부하를 준다) # cpulitmit을 실행하는데 cpu는 2개 vm(메모리 작업)은 1개를 작업 시작하고 30초 후 작업 종료 이 과정을 백그라운드에서 실행하고 작업 상태를 실시간으로 보여줘 sudo cgexec -g cpu:/cpulimit stress --cpu 2 --vm 1 --timeout 30s \u0026amp; top # cgroup 삭제 sudo cgdelete -g cpu:/cpulimit # memory 제한 실습 # memorylimit 이름의 그룹 생성 sudo cgcreate -g memory:/memorylimit # 512MB로 메모리 제한 설정 echo $((512 * 1024 * 1024)) | sudo tee /sys/fs/cgroup/memorylimit/memory.max # 메모리 시스템 부하 주기 및 0.5초 마다 memory.current 파일 내용 출력 sudo eegexec -g memory:/memorylimit stress --vm-byte 1024M --vm 1 --timeout 30s \u0026amp; watch -n 0.5 cat /sys/fs/cgroup/memorylimit/memory.current # cgroup 삭제 sudo cgdelete -g memory:/memorylimit NameSpace 개념 프로세스가 시스템 리소스를 격리하여 독립된 환경에서 실행되도록 하는 기술 컨테이너 기술에서 중요하게 사용 종류 Mount Namespace : 파일 시스템 마운트를 격리하여 각각 독립적인 파일 시스템 트리를 갖고 있다. Process ID Namespace : 프로세스 ID 격리하고 독립된 프로세스 ID 공간을 가지므로, 네임스페이스 마다 동일한 PID를 가질수 있다. Network Namespace(net) : 네트워크 장치, IP 주소, 포트 번호 등을 격리하여 독립적인 네트워크 스택을 가지며 네임스페이스 간 장치를 독립적으로 사용 가능 User Namespace : 사용자와 그룹 ID를 격리하여 비루트 사용자가 네임스페이스 내에 루트 권한을 가질수 있다. IPC Namespace(ipc) : 프로세스간 통신(메시지, 큐, 세마포어, 공유 메모리 등)을 격리하여 타 네임스페이스와 충돌 없이 사용 가능하다. UTS Namespace(uts) : 호스트와 도메인 이름을 격리하여 독립적으로 사용 가능, 이는 컨테이너화 된 시스템 식별 정보를 별도 설정하기 유용하다. 사용법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 # Namespace 실습 환경 세팅 sudo apt-get update sudo apt-get install -y util-linux # 새 마운트 네임스페이스 에서 관리자 권한으로 새로운 bash 셸 실행 sudo unshare --mount /bin/bash # 셸 안에 /mnt/test 디렉토리 생성 mkdir /mnt/test # tmpfs 타임의 임시 파일 시스템을 /mnt/test 에 마운트(운영체제에서 파일 시스템을 특정 디렉토리에 연결하여 사용할 수있도록 하는 과정) mount -t tmpfs none /mnt/test # \u0026#34;Hello from Mount Namespace\u0026#34;라는 텍스트를 /mnt/test/hello.txt 파일에 작성 echo \u0026#34;Hello from Mount Namespace\u0026#34; \u0026gt; /mnt/test/hello.txt # 방금 작성 hello.txt의 내용 출력 cat /mnt/test/hello.txt # 새롭게 만든 마운트 네임스페이스(현재 셸) 종료 exit # 호스트 네임스페이스에서 /mnt/test 디렉토리의 내용 나열 ls /mnt/test # PID Namespace 실습 # PID 네임 스페이스 생성 sudo unshare -pid -fork /bin/bash # 생성된 PID 네임 스페이스 안에 실행 중인 모든 프로세스 출력 ps -none # 현재 bash 쉘의 프로세스 id 출력 echo $$ #PID 네임 스페이스 bash 쉘 종료 exit # 기존 PID 네임스페이스로 위 동작과 동일 ps -e echo $$ # User(UID, GID) Namespace 실습 # USER 네임 스페이스 생성 sudo unshare --user /bin/bash # 현재 id 정보 출력 id # root_test_file이라는 이름으로 빈 파일 생성 touch /root_test_file # 생성한 빈 파일 정보 출력 및 나가기 ls -l /root_test_file exit # 관리자 권한으로 root_test_file 삭제 sudo rm /root_test_file # UTS Namespace # 현재 시스템 호스트명 출력 hostname # 새로운 UTS 네임스페이스 생성 후 bash 쉘 실행 sudo unshare --uts /bin/bash # 새로운 UTS 안에 호스트 명을 kakao로 변경 후 출력 후 나가기 hostname kakao hostname exit # 기존 호스트 네임 출력 hostname Chroot(Change Root) 개념 특정 디렉토리를 시스템의 루트 디렉토리로 설정하여 그 안에서 실행되는 프로그램이 해당 디렉토리를 루트로 인식(chroot jail) 시스템 일부를 격리하여 제한된 환경에서 테스트나 보안 목적으로 사용 특정 디렉토리를 빠져나가지 못하기 때문에 감옥 이라고도 부른다. 주요 기능 보안 : 사용자가 시스템의 다른 부분에 접근하지 못하도록 한다. 테스트 : 새로운 소프트웨어나 설정을 격리된 환경에서 테스트 사용법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # /mychroot 디렉토리 아래에 여러 디렉토리를 한번에 생성 sudo mkdir -p /mychroot/\u0026lt;bin,lib,lib64,dev,etc,proc,sys\u0026gt; # /bin 디렉토리의 모든 파일과 /bin/bash, /bin/ls, /bin/cat이 의존하는 모든 라이브러리 파일을 디렉토리 구조를 유지한 채 /mychroot로 복사 sudo cp /bin/* /mychroot/bin/ for lib in $(ldd /bin/bash /bin/ls /bin/cat | grep -o \u0026#39;/lib[^ ]*\u0026#39;); do sudo cp --parents \u0026#34;$lib\u0026#34; /mychroot; done # mychroot 환경에서 proc, sys, dev를 사용할 수 있도록 마운트 하는 작업을 수행한다. sudo mount -t proc proc /mychroot/proc sudo mount -t sysfs sys /mychroot/sys sudo mount --bind /dev /mychroot/dev # mychroot 디렉토리로 변경하고 쉘을 실행해 root 인 것처럼 동작하게 하는 작업 sudo chroot /mychroot /bin/bash # 현재 루트 디렉토리의 내용 나열 ls / # /etc/kakao에 파일 저장 후 출력 및 쉘 종료 echo \u0026#34;Hello from chroot\u0026#34; \u0026gt; /etc/kakao cat /etc/kakao exit # 마운트한 proc, sys, dev를 언마운트 한 후 mychroot 디렉토리 및 하위 모든 내용 삭제 sudo umount /mychroot/proc sudo umount /mychroot/sys sudo umount /mychroot/dev sudo rm -rf /mychroot UDS(Unix Domain Socket) 개념 동일한 컴퓨터 내의 프로세스 간 통신(Inter-Process Communication, IPC)를 위한 매커니즘 중 하나 TCP/IP 네트워크 소켓과 유사하지만 로컬 파일 시스템을 통해 통신 주요 특징 로컬 통신 : 호스트 내에세 실행되는 프로세스 간의 통신을 지원해 네트워크 소켓에 비해 성능 우수 파일 시스템을 이용한 주소 지정 : 파일 시스템 경로를 사용해 소켓을 식별하며 /tmp/mysocket과 같은 파일 경로 사용 데이터 전송 속도 : 네트워크 계층을 거치지 않아 빠른 데이터 전송 가능(네트워크 스택의 오버헤드를 줄이기 때문) 보안 : 파일 시스템 권한 설정을 통해 접근 제어, 특정 사용자나 프로세스만 소켓에 접근하도록 제한 사용법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # file name : server.py import socket import os SOCKET_FILE = \u0026#34;/tmp/mysocket\u0026#34; if os.path.exists(SOCKET_FILE): os.remove(SOCKET_FILE) server = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) server.bind(SOCKET_FILE) server.listen(1) print(\u0026#34;서버가 클라이언트를 기다리고 있습니다...\u0026#34;) conn, addr = server.accept() print(\u0026#34;클라이언트 연결 수락\u0026#34;) while True: data = conn.recv(1024) if not data: break print(\u0026#34;클라이언트로부터 받은 데이터:\u0026#34;, data.decode()) conn.sendall(data) conn.close() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # file name : client.py import socket SOCKET_FILE = \u0026#34;/tmp/mysocket\u0026#34; client = socket.socket(socket.AF_UNIX, socket.SOCK_STREAM) client.connect(SOCKET_FILE) message = \u0026#34;안녕하세요, 서버!\u0026#34; client.sendall(message.encode()) data = client.recv(1024) print(\u0026#34;서버로부터 받은 데이터:\u0026#34;, data.decode()) client.close() 1 2 3 # 하나의 터미널에서 작업 시 python3 server.py \u0026amp; python3 client.py OverlayFS 개념 여러 디렉토리를 하나의 계층적 파일 시스템으로 병합 후 제공 읽기 전용 파일 시스템에 쓰기 가능한 레이어를 추가해 기본 파일 시스템을 변경 없이 수정, 추가 가능 주요 특징 파일 시스템 계층화 : 읽기 전용 및 쓰기 가능한 계층을 병합 후 사용 스냅샷 및 버전관리 : 파일 시스템의 상태를 스냅샷으로 저장 필요 시 복원 컨테이너 : Docker와 같은 컨테이너 기술에서 이미지 레이어링을 위해 사용 구조 Lowerdir : 읽기 전용 파일 시스템 Upperdir : 쓰기 전용 파일 시스템 Workdir : Lowerdir과 Upperdir의 변경사항 추적을 위한 디렉토리, Docker에서 해당 디렉토리가 없으면 동작x Merged : Lowerdir과 Upperdir을 합쳐서 만든 현재 상태의 파일 시스템 디렉토리 작동방식 새로운 파일 생성 : Upperdir에 파일 생성 기존 파일 읽기 : 파일이 Upperdir에 있으면 Upperdir에서 읽고 없으면 Lowerdir에서 읽음 기존 파일 수정 : 파일이 Upperdir에 없으면 Lowerdir에서 Upperdir로 복사 후 수정 파일 삭제 : 파일이 Upperdir에 있으면 삭제, Lowerdir에 있으면 Upperdir에 삭제 마커 생성 사용법 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 sudo mkdir -p /lower /upper /work /merged # /lower, /upper, /work, /merged 디렉토리를 생성합니다. (필요시 부모 디렉토리도 함께 생성) echo \u0026#34;Lowerdir 입니다\u0026#34; | sudo tee /lower/lowerfile.txt # \u0026#34;Lowerdir 입니다\u0026#34;라는 문자열을 /lower/lowerfile.txt 파일에 씁니다. (파일이 없으면 생성) echo \u0026#34;Upperdir 입니다\u0026#34; | sudo tee /upper/upperfile.txt # \u0026#34;Upperdir 입니다\u0026#34;라는 문자열을 /upper/upperfile.txt 파일에 씁니다. (파일이 없으면 생성) sudo mount -t overlay overlay -o lowerdir=/lower,upperdir=/upper,workdir=/work /merged # lowerdir로 /lower, upperdir로 /upper, workdir로 /work를 사용하여 /merged에 overlay 파일 시스템을 마운트합니다. ls /merged # /merged 디렉토리의 내용을 나열합니다. # \u0026gt;\u0026gt; merged에서 lowerfile.txt와 upperfile.txt 확인 cat /merged/lowerfile.txt # /merged 디렉토리 안의 lowerfile.txt 파일의 내용을 출력합니다. cat /merged/upperfile.txt # /merged 디렉토리 안의 upperfile.txt 파일의 내용을 출력합니다. echo \u0026#34;Mergeddir 입니다\u0026#34; | sudo tee /merged/mergedfile.txt # \u0026#34;Mergeddir 입니다\u0026#34;라는 문자열을 /merged/mergedfile.txt 파일에 씁니다. (파일이 없으면 생성) ls /upper # /upper 디렉토리의 내용을 나열합니다. (mergedfile.txt가 여기에 나타납니다) sudo umount /merged # /merged 디렉토리에 마운트된 파일 시스템을 언마운트합니다. sudo rm -rf /lower /upper /merged /work # /lower, /upper, /merged, /work 디렉토리와 그 안의 모든 파일을 강제로 삭제합니다. ","date":"2024-07-08T22:32:35+09:00","permalink":"https://choiseungwoo98.github.io/p/linux-linux-%EC%8B%AC%ED%99%94/","title":"[Linux] Linux 심화"},{"content":" 리눅스에 대해 배웠다.\n처음 알게된 명령어도 많았지만\n하다보면 외워지겠지\u0026hellip;\n일단 정리정리..\n리눅스 유닉스 계열의 OS 중 하나로 전 세계적으로 널리 사용되고 있는 오픈 소스 소프트웨어이다. 다양한 시스템에서 동작하며 특히 서버, 데스크탑, 모바일 기기에서 사용 오픈소스 개념 오픈 소스 소프트웨어(OOS : Open Source Software)로 누구나 열람, 수정, 배포가 가능한 소프트웨어이다. 중요성 투명성 : 공개 소스로 동작 방식 확인 가능 협업과 혁신 : 누구나 수정, 배포가 가능해 빠른 소프트웨어 개선 비용 절감 : 라이센스 비용이 없거나 저렴함 자유와 통제 : 자유롭게 수정할 수 있는 권한 GPL License 자유 소프트웨어 재단에서 만든 라이선스로 자유롭게 사용할 수 있고 수정, 배포 할 수 있는 권리 보장 자유 소프트웨어 운동 사용, 수정, 공유의 자유를 보장하는 소프트웨어 소프트웨어는 사용자의 자유와 권리를 침해하지 않아야 한다는 철학 자유와 접근성을 증진하고 독점 소프트웨어에 대한 대안을 제공 리눅스 구조 어플리케이션 사용자가 직접 상호작용하는 단계로 빌드된 앱, 바이너리, 명령어, 빌드된 파일을 통틀어 어플리케이션이라고 한다. 주요 기능 사용자가 상호작용할 수 있는 인터페이스 제공 커널을 통한 시스템 리소스(CPU, Memory, I/O 장치 등)을 사용 쉘 어플리케이션이 커널에서 사용하는 명령어를 가려주고 쉘을 사용해 스크립트도 만들 수 있다. 주요 기능 명령어 해석 : 사용자가 입력한 명령어 해석, 실행하기 위해 시스템 콜 스크립트 실행 : 쉘 스크립트를 통해 여러 명령어 조합이나 여러 명령어를 일괄 실행 환경 관리 : 환경 변수 설정 및 관리 커널 OS의 핵심 부분으로 하드웨어와 상호작용하는 단계 주요 기능 프로세스 관리 : 프로세스 생성, 스케줄링, 종료 등을 관리 메모리 관리 : 가상 메모리, 페이징, 스왑 메모리등을 통해 효율적인 메모리 관리 가상 메모리 : 보조기억장치를 이용해 실제 사용 가능한 메모리보다 더 많은 메모리를 사용가능하게 하는 기법 페이징 : 메모리를 좀 더 효율적으로 사용하기 위해 고안된 기법으로 메모리를 일정 크기만큼 잘라서 사용하는 기법 스왑 메모리 : 실제로 사용하지 않는 나머지 부분(페이지)을 보조기억장치의 특정 영역(스왑 영역)으로 옮겨서 공간을 확보하는 기법 파일 시스템 관리 : 파일의 저장, 접근, 조작을 지원하는 파일 시스템 관리 장치 관리 : 하드웨어 장치와의 상호작용을 관리하고 장치 드라이버를 통한 추상화 보안및접근제어 : 사용자와 시스템 자원 간의 보안정책을 관리하고 적용 하드웨어 물리적인 컴퓨터 구성요소로 CPU, Memory, SSD, HDD, Network Interface 등 직접 통제하지 않고 커널의 추상화를 통해 관리할 수 있도록 간접적으로 접근 주요 기능 CPU: 명령어 처리 및 프로그램을 실행 Memory: 실행 중인 프로그램과 데이터를 저장 저장 장치: 데이터를 (반)영구적으로 저장 대표적인 Linux 배포판 Ubuntu Debian 계열중에 가장 유명한 배포판 쉬운 설계 및 직관적인 GUI 제공 방대한 레퍼런스 2년 단위의 버전 출시 및 5년간 유지보수로 보안성이 강하고 안정적 CentOS RHEL(RedHat Enterprise Linux)계열로 안정성과 보안이 뛰어나 주로 기업에서 많이 사용하는 OS 방대한 레퍼런스 CentOS 7까지는 무료였으나 CentOS 8부터는 유료로 제공 Arch Linux 경량화, 커스터마이징에 특화된 OS 자체 용량이 굉장히 작다. 패키지 매니저 APT Demian 계열에서 주로 사용하는 패키지 매니저 Demian : 여러 파생 배포판의 기반(Ex : Ubuntu, Linux Mint 등) 패키지 설치 시 의존성 패키지도 자동 설치 YUM/DNF RHEL 계열에서 주로 사용하는 패키지 RHEL(Red Hat Enterprise Linux) : 레드햇이 개발한 상용 리눅스 배포판, 주로 기업환경에서 사용되며 고성능, 안정성, 보안, 지원 서비스 제공 플러그인 시스템을 통해 기능 확장 가능 YUM보다 DNF를 사용하는 추세 권한 및 소유자 모든 파일 및 디렉토리는 사용자(User)와 그룹(Group)에 의해 소유(Ex : colton:KTB 라면 colton과 KTB에 속한 그룹의 소유) 사용자와 그룹 말고도 접근 권한을 지정 할 수 있다. R(Read) : 읽기 권한, cat으로 파일 내용 확인 가능 W(Write) : 쓰기 권한, vim, echo, sed 명령어 등으로 수정 가능 X(eXecute) : 실행 권한, sh, bash에 의해 실행될 수 있음 파일의 부여할 수 있는 권한은 Bit로 관리되며 Read 4, Write 2, Execute 1로 설정 한 파일이 갖는 모든 권한은 User, Group, Others(Ex : 754 라면 유저는 모든 권한, 그룹은 읽기 및 실행, 그 외는 읽기의 권한) 디렉토리 구조 Root Directory(/) : 시스템의 모든 디렉토리는 루트 하위에서 관리 bin(/bin) : 사용자 명령어가 저장되는 디렉토리(ls, cd, mv, rm, bash 등) lib(/lib) : 시스템, 어플리케이션의 공유 라이브러리가 저장 usr(/usr) : 앞서 설명한 디렉토리들이 모두 포함(앞선 디렉토리가 바라보고 있음) dev(/dev) : 장치 파일들이 저장되는 디렉토리(터미널, 널 장치 등 포함), 모든 장치가 파일 형태로 표시 etc(/etc) : 전반적인 시스템 설정 파일이 저장, 사용자 계정 정보, 암호정보, 호스트 네임/IP 매핑 파일 등 opt(/opt) : CLI 보다 GUI에서 자주 사용되는 디렉토리, 설치 매니저를 통해 설치된 어플리케이션이 주로 포함 proc(/proc) : 커널과 프로세스에 대한 가상 파일 시스템 저장(/proc/cpuinfo : CPU 정보, /proc/meminfo : 메모리 정보), 시스템 상태와 커널 정보등을 제공하며 동적으로 생성되는 파일들로 구성 home(/home) : 개인 디렉토리가 저장되는 위치, 기본적으로 권한과 소유자가 해당 유저에 맞게 설정 root(/root) : root 계정의 홈 디렉토리 tmp(/tmp) : 삭제되어도 문제 없는 파일이나 디렉토리와 같은 임시파일을 저장하는 디렉토리 명령어 정리 sudo : root(다른 사용자)의 명령 실행(sudo apt-get update) su : 사용자 변경(su ) adduser : 사용자 추가(adduser ) cat : 파일 내용 출력, 파일 연결 후 출력(cat ) usermod : 사용자 속성 변경(usermod -aG ) addgroup : 새로운 그룹 추가(addgroup ) vim : 강력한 텍스트 편집기(vim ) echo : 문자열 출력(echo \u0026ldquo;Hello world!\u0026rdquo;) cd(change Directory) : 디렉토리 변경(cd ..) chmod : 권한 변경(chmod \u0026lt;775 : 권한\u0026gt; ) ls -al(ll) : 자세한 내용을 포함한 목록 표시 ls : 디렉토리 내용 나열 mv : 파일, 디렉토리 이름 변경 혹은 이동(mv \u0026lt;temp2 : 기존이름\u0026gt; \u0026lt;temp : 바꿀 이름\u0026gt;) rm : 파일, 디렉토리 삭제(rm ) bash : bash 셀 실행 exit : 현재 스크립트 종료 passwd : 사용자 비밀번호 변경 shadow : /etc/shadow 파일에 저장된 암호화된 비밀번호 관리 hosts : /etc/hosts 파일 관리 apt-get : 데비안 기반 시스템에서 패키지 관리(apt-get \u0026lt;install : 동작\u0026gt; ) export : 셸 환경 변수 설정(export PATH=$PATH:\u0026lt;/new/path\u0026gt;) lsblk : 블록 장치 목록 표시 df -TH : 파일 시스템의 디스크 공간 사용량 표사 mkdir : 디렉토리 생성(mkdir ) rmdir : 빈 디렉토리 삭제(rmdir ) touch : 빈 파일 생성 or 기존 파일 타임 스탬프 변경(touch ) head : 파일의 처음 몇 줄 출력(head ) tail : 파일의 마지막 몇 줄 출력(tail ) pwd : 현재 경로 출력 whoami : 현재 사용자 이름 출력 top : 실시간 시스템 상태 모니터링 df -h : 디스크 사용량을 읽기 쉽게 표시 du -h : 디렉토리 사용량을 읽기 쉽게 표시(du -h ) ping : 네트워크 연결 상태 체크(ping www.google.com) curl : 데이터 전송 및 가져오기(curl www.google.com) ifconfig : 네트워크 인터페이스 구성 표시 및 변경 ps : 현재 실행중인 프로세스 목록 표시 find : 파일 시스템에서 파일과 디렉토리 검색(find -name ) service : 서비스 시작, 중지, 재시작, 상태 확인 등을 수행(service \u0026lt;start / stop / restart / status / \u0026ndash;status-all\u0026gt;) ip addr : 네트워크 인터페이스와 IP 주소 관리 및 사용 ","date":"2024-07-05T22:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/linux-linux-%EA%B8%B0%EC%B4%88/","title":"[Linux] Linux 기초"},{"content":" 네트워크에 대해 배웠는데 너무 모르겠다\u0026hellip;\n잘 따라 가려면 더욱 공부해야겠다..\n네트워크 둘 이상의 컴퓨터와 연결하는 링크의 조합이다. 물리적 네트워크는 어댑터, 케이블 및 전화선과 같은 장비이고 소프트웨어 및 개념 모델이 논리적 네트워크를 형성한다. 네트워크를 알아야 하는 이유 통신 및 데이터 교환(컴퓨터와 다른 장치들이 서로 통신하고 데이터를 교환할 수 있게 한다.) 분산 시스템 및 클라우드 컴퓨팅(여러 컴퓨터가 네트워크를 통해 하나의 시스템 처럼 작동, 대규모 데이터 처리 및 저장 분석 등) 해킹, 데이터유출 등 다양한 공격으로 부터 보호하기 위해 OSI 7 Layer, OSI 4 Layer OSI(Open System Interconnection : 개방형 시스템 상호 연결) : 다양한 통신 시스템이 통신 할 수 있도록 국제표준화기구에서 만든 개념 모델 OSI 7 Layer OSI 7 Layer\n응용 프로그램 계층(Application) - 데이터 사용자 사용하는 응용프로그램과 인터페이스를 제공하는 계층 네트워크 서비스에 접근 할 수 있는 인터페이스 제공 주요 프로토콜 : HTTP, FTP, SMTP, DNS, Telnet, SSH등 주요 프로토콜 포트: FTP(20 : 전송, 21 : 제어), SSH(22), SMTP(25), DNS(53), HTTP(80), POP3(110), NTP(123), HTTPS(443) Application Layer 프레젠테이션 계층(Presentation) - 데이터 데이터 표현 방식 정의 및 압축, 암호화, 인코딩 수행 데이터 형식 변환, 암호화, 압축 기능 제공 주요 프로토콜 : JPEG, MPEG, ASCII Presentation Layer 세션 계층(Session) - 데이터 양 끝단의 애플리케이션 간의 대화 관리와 동기화를 담당 세션 설정, 유지, 종료 관리 및 데이터 동기화 보장 주요 프로토콜 : RPC, NetBIOS Session Layer 전송 계층(Transport) - 세그먼트 데이터 전송의 신뢰성과 흐름 제이를 담당 데이터 분할, 재조립, 오류 복구등을 처리 예 : TCP(Transmission Control Protocol), UDP(User Datagram Protocol 주요 프로토콜 : TCP, UDP, SCTP Transport Layer 네트워크 계층(Network) - 패킷 데이터를 목적지까지 전달하는 경로 선택 및 패킷 라우팅 라우팅, 패킷 전달, 트래픽 제어등을 수행 예 : 라이터, IP 주소 주요 프로토콜 : IP, ICMP, ARP, OSPF, BGP Network Layer 데이터 링크 계층(Data Link) - 프레임 물리 계층에서 받은 데이터를 프레임 형태로 만들어 네트워크 계층으로 전달 에러 검출, 흐름제어, 접근 제어 기능 수행 예: 이더넷 스위치, MAC 주소 주요 프로토콜 : Ethernet, PPP(Point-to-Point Protocol), HDLC, WI-FI Data Link Layer 물리 계층(Physical) - 비트 데이터 전송을 위한 물리적 매체를 이용해 비트 스트림, 전송하는 계층 전기적, 기계적, 기능적 틍성을 정의 및 데이터 송수신 담당 예: 케이블, 허브, 리피트 등 주요 프로토콜 : Ethernet, RS-232, USB 등 Physical Layer 7 Layer vs 4 Layer\n단계가 많고 구조가 복잡해서 간단하고 인터넷 서비스에 적합한 4계층 모델이 개발됐다. 차이 계층별 장비 리피터(Repeater) 물리 계층 신호를 멀리 보내기 위한 증폭 장치 신호 감쇠 방지 및 전송 거리 증가 허브(Hub) 데이터 링크 계층 여러 장치를 하나의 네트워크로 연결시켜주는 장치 여러 컴퓨터 연결하지만 데이터 충돌 가능성이 있으며 Mac 주소를 인식하지 못한다. 브리지(Bridge) 데이터 링크 계층 두 개의 세그먼트를 연결 및 Mac 주소를 사용해 데이터 프레임 필터링 세그먼트 간의 트래픽 필터링 및 브로드캐스트 도메인 분할하려 충돌 감소 스위치 데이터 링크 계층 여러 장치를 연결하고 Mac 주소를 사용하여 프레임을 특정 포트로 전송 각 포트에 연결된 장치간 통신을 효율적으로 관리 및 충돌 도메인 분리해 성능 향상 라우터 네트워크 계층 다른 네트워크 간 데이터 전송, IP주소를 사용해 경로 결정 여러 네트워크를 연결해 데이터 패킷을 올바른 경로로 라우팅, 논리적 주소(IP 주소)를 기반으로 네트워크 트래픽 관리 주요 기술 Ethernet 가장 많이 사용되는 유선 네트워크, LAN(Local Area Network)에서 데이터 전송을 위해 사용 데이터를 프레임 단위로 나누어 전송(Mac 주소, 데이터 오류 검출 코드 등을 포함) IP(Internet Protocol) 네트워크에서 어떤 정보를 송수신하는 통신 규약, 호스트 주소를 지정 및 패킷 분할, 조립 기능 담당\n특징\n주소지정 : 고유한 IP 할당(IPv4, IPv6) 패킷 분할 및 재조립 : 큰 데이터 패킷을 분할 후 전송, 수신 측에서 재조립 경로 선택 : 패킷의 목적지까지 최적의 경로 선택 비연결형 : 패킷 전송 시 연결 설정 없이 독립적으로 전송 오류처리 : 패킷 전송 중 발생한 오류 처리 및 필요 시 재전송 생존시간 : 패킷의 수명을 설정해 네트워크가 무한정으로 떠돌지 않게함, 라우터를 거칠 때 마다 TTL 감소 프로토콜 식별 : 상위 계층 프로토콜 식별을 위해 헤더에 프로토콜 번호 포함 헤더 체크섬 : IP 헤더의 오류 검출을 위한 체크섬 필드 포함 패킷 형식 및 구조 : 헤더와 데이터로 구성되며 헤더는 목적지, 출발지 주소, TTL, 프로토콜 정보 등이 포함 IPv4 구조\n실습(WireShark) IPv4 구성 및 헤더 32비트로 이루어져 있으며 최근 주소 부족으로 개별적으로 부여할 수 없다. IPv4 주소 부족 현상을 해결하기 위해 네트워크 클래스가 등장했다. 네트워크 클래스 A Class : 1.0.0.1 ~ 126.255.255.254 B Class : 128.0.0.1 ~ 191.255.255.254 C Class : 192.0.0.1 ~ 223.255.255.254 D Class : 224.0.0.0 ~ 239.255.255.255 E Class : 240.0.0.0 ~ 254.255.255.254 특수 용도 0.0.0.0/8 : 자체 네트워크 10.0.0.0/8 : 사설 네트워크 127.0.0.0/8 : 루프백(자기자신) 169.254.0.0/16 : 링크 로컬(link local) 172.16.0.0/12 : 사설 네트워크 192.0.2.0/24 : 예제 등 문서에서 사용 192.88.99.0/24 : 6to4 릴레이 애니캐스트 192.168.0.0/16 : 사설 네트워크 198.18.0.0/15 : 네트워크 장비 벤치마킹 테스트 224.0.0.0/4 : 멀티캐스트 240.0.0.0/4 : 미래 사용 용도로 예약 서브넷, 서브넷팅, 서브넷마스크 서브넷 IP 네트워크 보다 더 작은 네트워크 네트워크에 효율성을 높이고 쉽게 만들기 위해 사용, 분할로 인해 트래픽을 줄이고 보안을 강화 할 수 있다 서브넷팅 IP 주소 공간을 여러 개의 작은 서브넷으로 나누는 과정 서브넷마스크 IP에 네트워크와 호스트 부분을 구분하기 위해 사용되는 비트 패턴 전송 계층 TCP 인터넷 같은 네트워크에서 데이터를 신뢰성 있게 전송하기 위해 설계된 연결 지향형 프로토콜 구조 3-way handshak : TCP 연결 설정 과정(SYN -\u0026gt; SYN-ACK -\u0026gt; ACK) 흐름제어 : 데이터 전송 속도 조절, 수신자 버퍼 오버플로우 방지(슬라이딩 윈도우) 혼잡제어 : 네트워크 혼잡 방지 및 해결, 패킷 손실과 지연 방지 UDP 데이터를 빠르고 효율적으로 전송하기 위해 설계된 비연결형 프로토콜 전송 순서와 신뢰성은 보장되지 않지만 속도와 효율성이 필요한 부분에 적합(ex : 실시간 스트리밍) 구조 데이터그램 : 비연결형 데이터 전송 단위, 순서 보장 x 스트리밍 : 실시간 연속 데이터 전송 방식, 주로 멀티 콘텐츠에 이용 HTTP, HTTPs 서버/클라이언트 모델에 따라 데이터를 주고 받기 위한 프로토콜, TCP/IP 위에서 동작 연결 상태를 유지하지는 않는다.(비연결형) -\u0026gt; 요청/응답 방식으로 동작, Cookie와 Session의 등장으로 비연결성, 비상태성 보완 암호화되지 않기 때문에 보안에 취약하다. HTTP Response : 200, 404, 500 등 캡슐화 동작 방식 네트워크 용어 정리 LAN(근거리 통신망) : 허브, 스위치로 연결하는 소큐모 네트워크, 주로 컴퓨터 장치와 연결된 네트워크를 말한다. MAN(대도시 통신망) : 도시와 도시의 통신망을 뜻하며 2개 이상의 LAN을 라우터, 브릿지로 연결, 고속 데이터 전송을 지원하며 통신사나 공공기관에서 운영한다. WAN(국가간 통신망) : 광역 네트워크로 지리적으로 넓은 영역에 걸쳐 여러 LAN, MAN을 연결하는 네트워크, 주로 Internet이라고 한다. WLAN(무선 근거리 통신망) : 라디오, 마이크로파(무선 랜 카드 등)를 이용해 데이터를 전송 VPN(사설 통신망) : 가상 사설망으로 공중 네트워크를 암호화된 방법으로 접속할 수 있는 기술 IP(Internet Protocol) : 인터넷을 통하는 네트워크에서 정보를 송수신하는 통신 규약 라우터 : 둘 이상의 패킷 전환 네트워크 또는 서브네트워크를 연결하는 장치, 네트워크 계층에서 동작한다. 라우팅 : 다양한 네트워크 간에 데이터를 전송하는 역할, 네트워크에서 패킷을 받아 목적지까지 최적의 경로를 결정 후 데이터 전달 패킷 : 네트워크에서 출발지와 목적지간에 라우팅되는 데이터 단위 포트 : 소프트웨어 기반이며 OS에서 관리하는 네트워크 연결이 시작되고 끝나는 가상의 지점 네트워크 케이블 유형 : 이더넷 케이블, 광섬유 케이블 등 프로토콜 : 데이터 교환 방식을 정의하는 규칙 체계 CIDR : 데이터 라우팅 효율성을 향상시키는 IP주소 할당 방법 VPC : 퍼블릭 클라우드 환경에서 사용할 수 있는 고객 전용 사설 네트워크 NAT : Private IP 주소로 외부와 통신할 수 없어 Public IP 주소로 변환(Ex : 공유기) 루프백 : localhost로 알려져 있으며 자신의 ip 스택을 통해 네트워크 인터페이스로 전송된 데이터를 동일한 시스템으로 다시 전송 멀티캐스트 : 하나의 송신자가 여러 수신자에게 동시에 데이터를 전송하는 방식 주로 스트리밍, 주식 거래 등 대규모 수신자에게 동일한 데이터를 효율적으로 전달해야 하는 경우 포트포워딩 : 외부 네트워크에서 특정 포트로 들어오는 트래필을 내부 네트워크의 특정 IP 주소와 포트로 전달하는 네트워크 설정 보수표현법 : 컴퓨터에서 음수를 표현하는 데 사용하는 방법, 1의 보수는 반전(1010 -\u0026gt; 0101), 2의 보수는 반전 후 1을 더함(1010 -\u0026gt; 0110) 포스트 작성 시 참고한 링크 네트워크 및 통신개념\n","date":"2024-07-04T22:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/network-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B0%9C%EB%85%90/","title":"[Network] 네트워크 개념"},{"content":" 어제 어수선한 분위기 속에 첫날이 마무리되고\n두번째 수업이 진행되었습니다.\n오늘은 클라우드 개론에 대해 배웠고 까먹지 않기 위해 정리해보고자 합니다.\n아키텍처 애플리케이션을 실행할 기반이 되는 온라인 플랫폼을 제공할 목적으로 클라우드 구축에 필수적인 모든 구성 요소 및 기능을 연결하는 방식 서비스를 구축할 때, 클라우드 서비스의 다양한 기능들을 이용하여 인프라 구축 그림을 그리는 것 아키텍처를 그리기 위한 배경지식들 OS(Operating System) 하드웨어를 사용하기 위해 필요한 소프트웨어이다. Ex : Windows, Mac, Linux 등 파일시스템 운영 체제에서 HD, SSD 또는 USB 플래시 드라이브와 같은 저장 장치에 있는 파일을 구성하고 관리하는 데 사용하는 구조이다. 클라우드에서도 서버 용량을 붙일 때 HD, SSD로 붙일지 선택하고 Network Block으로 만들어 붙인다. 따라서, VM에 있는 파일시스템 성능과 로컬에 성능은 다를 수 있다. NFS(Network File System), NBD(Network Block Device)와 같은 파일시스템에 대한 가상화도 많이 활용된다. VM (Virtual Machine) 가상화된 서버 보통 OnDemand 형태로 필요한 만큼 사용하거나 1년이나 3년 비용을 미리 할인되 가격으로 내는 Reserved 방식으로 활용한다 Spot Instance 형태로 저렴하게 사용 가능 단, 남는 리소스를 잠깐 빌려주는 형태라 강제로 서버가 회수될 수 있다. LB(Load Balancer) 네트워크 트래픽을 여러 서버로 분산시키는 역할 서버 이중화하는 경우 가장 많이 사용한다. 이중화를 통해 HA(고가용성)을 책임진다. HA : 바람직한 정도로 긴 시간동안 지속적으로 운영이 가능한 시스템이나 컴포넌트를 가리킨다. LB도 서비스 이기 때문에 느려질 수 있다. 트래픽 몰릴 것으로 예상되는 시점에 서버도 늘리지만, LB에 미리 부하를 줘서 LB를 구성하는 서버도 미리 늘려놓는다.\nPre-Warming 또는 Warm-Up이라고 부릅니다. 데이터베이스 데이터를 저장하고 관리하는 서비스 라이센스 규정에 의해 비슷한 서비스를 자체적으로 만들어 공급하는 경우가 많다(Ex : DynamoDB) 오픈소스를 운영하는 경우도 있다(Ex : Amazon RDS for MySQL, Elasticache) AWS는 최신 버전을 업데이트 해주지만 많은 클라우스 서비스들이 버전업, 유지보수를 해주지 않는 경우가 많다. CDN (Content Delivery Network) 자주 바뀌지 않는 리소스들을 캐싱하여 데이터를 전달하는 서비스 서버에서 리소스를 전달하면, 그 만큼 서버의 트래픽이 나가는데 이 트래픽을 CDN이 대신 책임져준다면 서버의 부담이 낮아진다. 캐싱을 사용해 서버가 리소스를 전달하는 것보다 효율적이다. 따라서, 자주 바뀌지 않는 리소스를 올리는게 좋습니다. MSA (Micro Service Architecture) 작은 독립적인 서비스들로 분할하여 운영하는 아키텍처로 VM이나 Container를 이용하여 운영되어야 한다. 보통 VM에 직접 올리는 형태에서 VM에 Container를 올려 운영하다가, 최종적으로는 EKS와 같은 쿠버네티스 시스템을 활용하는 형태로 고도화됩니다. 다층구조 소프트웨어 애플리케이션을 논리적으로 분리된 여러 계층으로 나누어 구성하는 아키텍처 스타일 다층 구조는 보통 프레젠테이션 계층(=프론트엔드 계층), 애플리케이션 계층(=백엔드 계층), 데이터 계층(=데이터베이스 계층)으로 나눈다.(고차원으로 갈수룩 더 다양한 계층이 생길 수 있다.) 다층 구조 종류 1티어 구조 프론트, 백, DB가 하나의 VM에서 돌고 있는 상황이다. VM이 죽는다면 모든 서버가 죽고 VM을 살리면 모든 서버를 살릴 수 있다. 2티어 구조 프론트, 백엔드 서버 구분 없이 하나의 서버에서 DB와 연결된 상황이다. 많이 사용되는 아키텍처, 안정성과 관리가 용이하다. 단점으로는 백엔드에서 나는 에러가 프론트에서도 난다.(Ex: 404페이지, 500페이지 등) 3티어 구조 프론트와 백엔드를 구별하고 백엔드에서 DB에 연결된 상황 인프라 운영 노하우가 있고 제품을 이해하고 있으면 가장 나은 방식이다. N티어 구조 백엔드에 역할을 다양하게 나누어 서로 API 통신하게 만드는 형태 대부분의 SaaS가 해당 형태로 운영된다. 다층구조 핵심 비즈니스 상황을 고려하여 티어를 선택 애플리케이션이 너무 커져서 모듈로 쪼갠다면 데이터 기반이 보편적이다.(결제 시스템, 유저 시스템 등) ","date":"2024-07-03T22:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/infra-%EC%95%84%ED%82%A4%ED%85%8D%EC%B2%98/","title":"[Infra] 아키텍처"},{"content":" 어제 어수선한 분위기 속에 첫날이 마무리되고\n두번째 수업이 진행되었습니다.\n오늘은 클라우드 개론에 대해 배웠고 까먹지 않기 위해 정리해보고자 합니다.\n클라우드 개념 컴퓨터 네트워크를 통해 인터넷 상에서 데이터 저장, 컴퓨팅 파워, 소프트웨어 등을 제공하는 기술이다. 즉, 인터넷 상에서 여러 리소스를 내가 원할 때 원하는 만큼 제공한다. 리소스 제공 통째로 빌려주는 방법 쉬운 방법이나, 내가 원하는 리소스랑 다를 수 있다. 원하는 리소스가 8코어 16기가 인데 16코어 32기가 서버가 존재한 경우 오버스펙이 된다. 사용자가 원하는 만큼 서버를 띄우는 방법 통째로 빌려주는 것이 아닌 큰 서버에서 사용자가 원하는 만큼 서버를 만들어 제공한다. 이때 사용하는 기술이 가상화(Virtualization)이다. 가상화(Virtualization) 개념\n물리적인 자원을 추상화하여 가상 자원을 만들어 관리하는 기술이다.(Ex : 안드로이드 애뮬레이터 등) 방법\n호스트 가상화 가장 쉬운 방법, window 혹은 mac에서 가상화 소프트웨어를 이용하여 서버를 만드는 방법이다.(Ex : Virtual Box, VMware Fusion 등) 호스트 가상화 하이퍼바이저 가상화 하드웨어에 하이퍼바이저를 설치하여 가상 자원을 만드는 방법이다.(Ex : Xen, KVM 등) OS 명령어를 하이퍼바이저가 모두 받아들이거나(Para-Virtualization, PV)\n하드웨어에서 OS 명령어를 이해하는 경우(Hardware Virtual Machine, HVM / Bare-Metal Hypervisor)가 있다. 엔지니어가 주로 사용하는 방법이다. 호스트 가상화와 가장 큰 차이점은 OS 위에 다른 OS를 띄우는 호스트 가상화와 달리\n하드웨어 위에 하이퍼바이저를 설치 후 그 위에 OS를 띄운다. 하이퍼바이저 가상화 컨테이너 가상화 컨테이너 관리 소프트웨어를 설치하여, 논리적으로 나누어 사용한다.(Ex : Docker, Linux Container 등) 컨테이너 가상화 AWS(Amazon Web Services)는 어떤 가상화를 사용할까? AWS EC2에서는 초반에 PV 방식을 사용하다가 HVM 방식을 사용하고 있으며, 최근 Nitro System을 사용하기 시작했다. AWS ECS에서는 컨테이너 가상화를 활용 중이다. 가상화 종류 서버 가상화 하나의 물리적 서버를 여러 가상 서버로 분할하여 사용 데스크탑 가상화 사용자의 데스크탑 환경 가상화 애플리케이션 가상화 애플리케이션을 가상 환경에서 실행하여 운영 체제와 분리 네트워크 가상화 물리적 네트워크 자원을 가상화하여 여러 가상 네트워크 생성 스토리지 가상화 물리적 스토리지를 추상화하여 논리적 스토리지 풀 생성 Virtual Machine과 Bare Metal Virtual Machine(VM) 가상 머신. 가상화 방식(PV or HVM)기반의 서버 대부분의 클라우드 내 서버는 VM 방식 사용 Bare Metal(BM) 큰 서버에서 분할해 제공하는 VM 방식과 달리 통째로 서버를 제공해주는 방법 필요한 CPU, Memory, Storage 만큼 하드웨어를 만들어 전달 Virtual Machine vs Bare Metal VM은 같은 하드웨어 위에서 분할하여 사용하므로\n한 사용자가 대량으로 리소스를 사용하면 하이퍼바이저에 영향이 가고 다른 사용자에게 까지 영향을 미칠수 있다.\n따라서, 안정적으로 좋은 성능을 요구한다면 BM을 비용 절감을 요구한다면 VM을 사용을 추천한다. CPU와 vCPU CPU 실제 하드웨어 자원, 물리적인 서버에서 실제 연산 vCPU 가상화 환경에서 물리적 CPU 자원을 추상화한 자원, VM에 할당된 가상 자원 CPU vs vCPU 두 자원은 엄연히 다른 자원이다. ","date":"2024-07-03T22:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/infra-%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-%EA%B0%9C%EB%85%90/","title":"[Infra] 클라우드 개념"},{"content":" 어제 어수선한 분위기 속에 첫날이 마무리되고\n두번째 수업이 진행되었습니다.\n오늘은 클라우드 개론에 대해 배웠고 까먹지 않기 위해 정리해보고자 합니다.\n가상화 기술 클라우드 서비스(IaaS : Infrastructure as a Service 혹은 CSP : Cloud Service Provider) 각종 자원들을 가상화하여 서비스 제공(서버, 네트워크, 스토리지 등) 기본 기능 : Compute, Network, Storage, Container, Database, Security, Ai 등 AWS, GCP, Kakao Cloud 등 플랫폼 기반 서비스(PaaS : Platform as a Service) 본인 애플리케이션을 쉽게 업로드하여 서비스 활용 가상화된 자원을 자동으로 할당받아 애플리케이션이 실행 Heroku, Vercel, Netlify, 카페24 등 솔루션 기반 서비스(SaaS : Software as a Service) 사용자의 니즈가 반영된 애플리케이션이 가상화된 자원을 할당받아 곧바로 서비스 제공 사용량에 따른 과금 정책이 대부분 구글 드라이브, 드롭박스, 네이버 MyBox등 대부분의 서비스가 여기에 속한다. 가상화 기술 집중적으로 공부해야하는 가상화 기술 대부분의 기업이 IaaS를 통해 SaaS를 출시한다. IaaS를 하는 기업은 대기업 위주이며(네이버 클라우드, 카카오 클라우드 등) 대부분의 클라우드는 IaaS를 이용해 SaaS를 개발한다. 클라우드 시장 보통 Iaas, PaaS, SaaS로 나누어 보고 IaaS 시장에서 가장 많이 사용되는 서비스는 현재 AWS다. IaaS를 만든다는 뜻 openStack 등의 솔루션을 통해 각 리소스를 가상화하고 서비스를 만드는것 여기에 흥미가 있다면 C/C++/Python 등을 공부하여 openStack을 활용해보는 것이 좋다. 다만, 현재로써는 석박사 과정이 필수이다. 자주 사용하는 기능 가장 기본적으로 Network를 아용하여 네트워크 구조 세팅 세팅된 Network 위에 Compute를 이용한 서버 구축 Database를 이용한 애플리케이션 DB 연결 Storage를 이용하여 애플리케이션에서 나오는 로그와 같은 파일 저장 그 외로 Security를 통해 보안 강화, AI를 통해 AI 서비스 붙이기\n즉, 이외에는 필요한 것들을 찾아 붙이는 방식 ","date":"2024-07-03T18:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/virtualization-%EA%B0%80%EC%83%81%ED%99%94-%EA%B8%B0%EC%88%A0/","title":"[Virtualization] 가상화 기술"},{"content":" 어제 OT를 잘 마치고 오늘 첫번째 수업 날 입니다!\n오늘은 별다른 수업 없이 ZEP에 접속하고 노션(단체, 개인 목표를 작성)을 만들었습니다. 진도를 나가지 않아 엄청 어수선한 분위기 속에 어떻게 되련지\u0026hellip;. 아침에 말씀해주셨던 부분 중 일부분을 찾아보고 작성하였습니다.\n쿠버네티스 컨테이너화 된 애플리케이션의 자동화(Deploy, Scaling 등을 제공) 하는 시스템 쿠버네티스를 운영하기 위한 서버가 따로 필요하다. 항상 쿠버네티스가 솔루션인가는 고민해볼 필요가 있다. 서버의 이중화는 반드시 필요한가? 정답은 없는 부분이라 섣부르게 답변하기 어렵지만 내 생각을 정리하자면 반드시 필요하지는 않다고 생각한다.\n주식, 게임과 같은 실시간 서비스거나 트래픽이 많은 대규모 어플리케이션을 운영하는 경우 필요하다고 생각하지만. 사내에서 인트라넷, 비즈니스에 큰 영향이 가지 않는 경우 이중화를 하게 되면 비용적인 문제가 발생할 수 있다고 생각한다.\n따라서, 서비스의 특징과 상황을 고려하여 이중화를 진행해야 한다고 생각합니다.\n안정성 vs 효율 개발자는 항상 기로에 놓이는 것 같습니다.\n새로운 기술을 채택하여 효율적으로 작업하거나 기존의 기술을 채택하여 안정적으로 작업하거나\n이것도 마찬가지로 정답은 없지만 그때그때 상황에 맞게 사용할 수 있도록 소통 및 판단하는 능력이 중요할 것 같습니다.\n나한테 이득이 되는 경험 서비스 운영 도메인 붙인 서비스 리소스 모터링(스케일인 / 스케일아웃) 개인정보처리방침과 이용약관 이해하고 회원가입 데이터 관리 db를 클라우드에 깔기 백업 자동화 데이터베이스 관리 애플리케이션 보안 Token 기반으로 api가 동작하도록 만들어보기 가장 쉬운 방법 세션, 토큰, key(하드하게 넣으면 탈취 당할 수 있음, 파일을 따로 둔다.) api 파라미터를 조작하여 다른 계정의 데이터를 가져올 수 없게 만들기 주요 3rd Party Key들을 보관할 때. 하드코딩 말고 밖으로 배서 관리하기 Vault을 통해 관리하기 클라우드 엔지니어가 알고 있으면 좋은 것들(추후에 포스트로 작성 예정) 쿠버네티스 네트워크 -\u0026gt; 20240704 작성 리눅스 보안 장애 대응 프로세서 HA(고가용성) Absible Terraform 온프레미스 방식 ssh sre kisa MongoDB Atlas(몽고 디비를 클라우드 서비스로 제공) session token GIB ","date":"2024-07-02T22:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/diary-%EB%B6%80%ED%8A%B8%EC%BA%A0%ED%94%84-%EC%8B%9C%EC%9E%91%ED%81%B4%EB%9D%BC%EC%9A%B0%EB%93%9C-ot/","title":"[Diary] 부트캠프 시작(클라우드 OT)"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다. 오늘의 질문! String 클래스의 메서드는 무엇이 있을까?\n오늘은 해당 질문에 대한 답변을 정리해보려 한다.\nlength(): 문자열의 길이를 반환합니다. isEmpty(): 문자열이 비어있는지 확인합니다. equals(Object obj): 주어진 객체와 문자열이 동일한지 비교합니다. equalsIgnoreCase(String str): 대소문자를 무시하고 문자열을 비교합니다. indexOf(String str): 지정된 문자열이 처음으로 나타나는 인덱스를 반환합니다. substring(int beginIndex): 지정된 인덱스부터 문자열 끝까지의 부분 문자열을 반환합니다. substring(int beginIndex, int endIndex): 지정된 범위의 부분 문자열을 반환합니다. split(String regex): 정규식을 기준으로 문자열을 나누어 배열로 반환합니다. toUpperCase(): 문자열의 모든 문자를 대문자로 변환합니다. toLowerCase(): 문자열의 모든 문자를 소문자로 변환합니다. trim(): 문자열의 앞뒤 공백을 제거합니다. replace(char oldChar, char newChar): 지정된 문자를 새로운 문자로 치환합니다. charAt(int index): 지정된 인덱스에 위치한 문자를 반환합니다. contains(CharSequence sequence): 주어진 문자열 또는 문자 시퀀스를 포함하는지 확인합니다. matches(String regex): 정규식과 일치하는지 확인합니다. concat(String str): 다른 문자열을 현재 문자열에 연결합니다. startsWith(String prefix): 주어진 접두어로 시작하는지 확인합니다. endsWith(String suffix): 주어진 접미어로 끝나는지 확인합니다. compareTo(String anotherString): 다른 문자열과의 사전 순서 비교를 수행합니다. compareToIgnoreCase(String str): 대소문자를 무시하고 사전 순서 비교를 수행합니다. format(String format, Object\u0026hellip; args): 지정된 포맷으로 문자열을 생성합니다. valueOf(primitive data type): 기본 데이터 타입의 값을 문자열로 변환합니다. getBytes(): 문자열을 바이트 배열로 변환합니다. 포스트 작성 시 참고한 링크 문자열 메서드 ","date":"2023-08-20T02:35:44+09:00","permalink":"https://choiseungwoo98.github.io/p/string_method/","title":"String_Method"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다. 오늘의 질문! 문자열을 반전 시키는 가장 좋은 방법은 무엇인가?\n오늘은 해당 질문에 대한 답변을 정리해보려 한다.\n문자열을 반전 시키는 가장 좋은 방법이란 문자열을 반전 시키는 방법은 정말 많이 있다.\n예를 들어 반복문을 사용하는 방법, 라이브러리 함수를 이용하는 방법, 재귀함수를 이용하는 방법 등 정말 다양한 방법이 있다.\n이 중에서 효율이 좋다고 생각하는 방법 1가지에 대해 알아보고자 한다.\nStringBuilder를 사용해 문자열 반전 시키기 자바에서 문자열을 반전 시키는 가장 일반적인 방법으로 StringBuilder의 reverse() 메서드를 사용하는 방법이다.\n이 방법은 가장 효율적인 방법 중 하나입니다.\n문자열은 불변 객체이기 때문에 문자열을 직접 수정을 시도하면 매번 힙 영역의 새로운 문자열 객체를 생성하게 된다.\n이는 매번 Garbage가 쌓여 메모리 효율을 떨어트릴 수 있으며 StringBuilder를 사용하면 이러한 비 효율성을 줄여줄 수 있다.\n1 2 3 4 5 6 public class reverseString { String origin = \u0026#34;Hello World\u0026#34;; String reverse = new StringBuilder(origin).reverse().toString(); System.out.println(reverse); // 출력: \u0026#34;dlroW olleH\u0026#34; } 포스트 작성 시 참고한 링크 자바 문자열 반전 ","date":"2023-08-20T01:22:51+09:00","permalink":"https://choiseungwoo98.github.io/p/java-%EB%AC%B8%EC%9E%90%EC%97%B4%EC%9D%84-%EB%B0%98%EC%A0%84-%EC%8B%9C%ED%82%A4%EB%8A%94-%EA%B0%80%EC%9E%A5-%EC%A2%8B%EC%9D%80-%EB%B0%A9%EB%B2%95/","title":"[Java] 문자열을 반전 시키는 가장 좋은 방법"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다.\n오늘은 여러가지 질문 중 String에 대해 알아보고자 한다. String은 기본 데이터 타입인지? 문자열을 조작하는 클래스는 무엇이 있는지?\nString은 무엇인가? 기본 자료형(int, float, char, boolean)처럼 자주 사용되는 class이다.\nString은 이 기본 자료형들과는 다르게 참조 자료형 class이다.\n참조 자료형이란 객체 자체에 값을 가지는 것이 아닌 객체에는 referenece(주소) 값을 갖고 있고 해당 reference에 객체의 값이 있는 형태다.\nString은 기본 데이터 타입인가? 위에서도 말씀 드렸지만 String은 기본 데이터 타입이 아닌 참조 자료형 클래스 이다.\n기본 타입과 달리 heap 영역에 생성된다.\n1. 문자열 생성 및 비교 아래와 같이 문자열을 리터럴로 생성한다면 literalName이라는 변수는 스택 영역에 저장되고 문자열인 \u0026ldquo;최승우\u0026quot;는 힙 영역에 String 객체로 생성된다.\nliteralName이라는 변수에는 힙 영역에 저장된 주소 값이 저장된다.\n따라서 문자열 리터럴이 동일한 경우 같은 주소 값을 저장하게 돼 ==와 .equals 상관 없이 같다고 나온다.\n다만, new 연산자를 사용하여 객체를 생성하면 문자열의 값이 같더라도 다른 주소 값을 저장하기 때문에 ==을 사용하면 다르다고 출력한다.\n따라서 저장된 값을 비교하고 싶으면 equals()를 사용해야 한다.\n1 2 3 4 5 6 7 public class StringTest { String literalName = \u0026#34;최승우\u0026#34;; String newName = new String(\u0026#34;최승우\u0026#34;); System.out.println(literalName == newName); // false System.out.println(literalName.equals(newName)); // true } 2. 가변성을 갖고 있는 StringBuilder와 StringBuffer 들어가기 앞서, String은 불변속성을 갖는다.\n만약, 아래와 같이 sayHello라는 변수에 안녕!이라는 값을 리터럴로 생성하면 힙 영역에 String 객체로 생성하고,\n그 이후 \u0026quot; 승우야!\u0026ldquo;라는 값을 추가하게 되면 해당 객체에 \u0026ldquo;안녕 승우야!\u0026rdquo; 라는 값으로 변경했다고 생각할 수 있다.\n하지만 기존에 \u0026ldquo;안녕!\u0026ldquo;이 들어가 있던 객체를 참조하던 sayHello 변수는 힙 영역에 \u0026ldquo;안녕 승우야!\u0026ldquo;의 값을 갖고 있는 객체를 새로 생성한 후 해당 주소 값을 바라보고 있도록 변경된 것이고\n처음 생성되었던 \u0026ldquo;안녕!\u0026ldquo;이라는 값을 갖고 있는 메모리 영역은 Garbage로 남아 있다가 GC(Garbage Collection)에 의해 사라지게 된다.\n이는, String 클래스는 불변하며 문자열을 수정하는 시점에 새로운 String 인스턴스가 생성된다는 것을 의미한다.\n이 처럼 String은 불변하기 때문에 빈번한 수정이 있는 경우 힙 메모리 영역에 많은 Garbage가 쌓이므로 성능의 치명적인 영향을 끼친다.\n그래서 가변성을 갖고 있는 StringBuilder와 StringBuffer 클래스를 도입했다.\n이 두 클래스는 .append(), .delete()를 이용하여 동일 객체내에서 문자열을 변경하는 것이 가능하다.\n문자열의 추가, 수정, 삭제가 빈번하게 발생하는 경우 이 두가지 클래스를 사용하는 것이 적합하다.\n3. StringBuffer, StringBuilder의 차이점 가장 큰 차이점은 동기화 유무 이다.\nBuffer는 동기화 키워드를 지원하여 멀티 쓰레드 환경에서 안전하다는 점(thread-safe)\n참고로 String도 불변성을 갖기 때문에 멀티 쓰레드 환경에서의 안성정을 갖고 있다. Builder는 동기화를 지원하지 않기 때문에 멀티 쓰레드 환경에서 사용하는 것은 적합하지 않지만 동기화를 고려하지 않는 만큼 단일 쓰레드에서의 성능은 Buffer보다 뛰어나다. 4. 정리 간단히 정리하면, String은 불변성으로 인해 안전하고 쓰기 쉽지만 문자열을 자주 조작하는 경우 오버헤드가 발생할 수 있습니다. StringBuilder는 가변성으로 인해 자주 조작하는 경우 효율적이고, 단일 스레드 환경에서 사용하기 적합합니다. StringBuffer는 StringBuilder와 유사하게 가변성을 제공하면서 멀티스레드 환경에서도 안전하게 사용할 수 있습니다. 따라서 단일 스레드 환경에서는 StringBuilder를, 멀티스레드 환경에서는 StringBuffer를 선호하는 것이 좋습니다. 문자열 연산이 적고 멀티 쓰레드인 경우 : String\n문자열 연산이 많고 멀티 쓰레드인 경우 : StringBuffer\n문자열 연산이 많고 단일 쓰레드이거나 동기화를 고려하지 않아도 되는 경우 : StringBuilder\n포스트 작성 시 참고한 링크 String 클래스 문자열 조작 클래 ","date":"2023-08-19T18:11:51+09:00","permalink":"https://choiseungwoo98.github.io/p/java-string%EC%9D%80-%EA%B8%B0%EB%B3%B8-%ED%83%80%EC%9E%85%EC%9D%B8%EA%B0%80-%EA%B7%B8%EB%A6%AC%EA%B3%A0-stringbuffer-stringbuilder/","title":"[Java] String은 기본 타입인가? 그리고 StringBuffer, StringBuilder"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다.\n오늘은 여러가지 질문 중 Math 클래스에 대해 알아보고자 한다.\nMath 클래스란? 자바에서 제공되는 유틸리티 클래스로 자주 사용하는 상수들과 함수들을 미리 구현해 놓은 클래스입니다.\n1. Math에 정의된 대표적인 상수 Math.PI : 원주율 π (약 3.141592653589793) Math.E : 자연 상수 e (약 2.718281828459045) 2. Math에 정의된 대표적인 메서드 abs(int a) / abs(long a) : 정수의 절댓값을 반환합니다. ceil(double a) : 주어진 숫자보다 크거나 같은 최소 정수를 반환합니다. floor(double a) : 주어진 숫자보다 작거나 같은 최대 정수를 반환합니다. round(float a) / round(double a) : 주어진 숫자를 반올림하여 long 형태로 반환합니다. min(int a, int b) / min(long a, long b) : 두 정수 중 작은 값을 반환합니다. max(int a, int b) / max(long a, long b) : 두 정수 중 큰 값을 반환합니다. sqrt(double a) : 주어진 숫자의 제곱근을 반환합니다. pow(double a, double b) : a의 b승을 반환합니다. sin(double a), cos(double a), tan(double a) : 삼각 함수 값들을 반환합니다. random() : 0 이상 1 미만의 난수를 반환합니다. (0.0 \u0026lt;= x \u0026lt; 1.0) 3. 각 메서드 사용 및 결과 Math.abs(-1.5) : 1.5 Math.ceil(-1.5) : -1.0 Math.floor(-1.5) : -2.0 Math.round(-1.5) : -2 Math.min(-1.5, 3.0) : -1.5 Math.max(-1.5, 3.0) : 3.0 Math.sqrt(-1.5) : NaN (Not a Number : 제곱근이 실수 범위 내에 없기 때문에 이 경우 허수와 관련된 복소수 연산이 필요하며 Math 클래스에서는 지원하지 않음) Math.sqrt(4) : 2.0 Math.pow(-1.5, 2.0): 2.25 Math.sin(-1.5): -0.9974949866040544 Math.cos(-1.5): 0.0707372016677029 Math.tan(-1.5): -14.101419947171719 Math.random(): [0.0, 1.0) 범위의 난수 (실행할 때마다 값이 달라집니다) Math.random() * 100 : 0 ~ 99 까지 랜덤으로 1가지의 수 포스트 작성 시 참고한 링크 Math 클래스 ","date":"2023-08-19T17:49:27+09:00","permalink":"https://choiseungwoo98.github.io/p/java-math-%ED%81%B4%EB%9E%98%EC%8A%A4/","title":"[Java] Math 클래스"},{"content":" 프로젝트를 하다보면 각자 다른 네이밍을 사용하다 보니 다른 사람이 작업한 코드를 보면 헷갈릴 때가 있다.\n그래서 나온것이 표준 네이밍 규칙이며 보통 권장사항 이다보니 많이 놓치고 있어서 한번 정리해보려 한다!\n오늘 정리할 네이밍 규칙은 Java 이다.\n1. 네이밍 규칙이란? 프로그래밍에서 변수, 함수, 클래스, 상수, 패키지 등의 작성할 때 따르는 규칙이다. 이러한 규칙을 따르면 코드의 가독성이 좋아지고 일관석 있게 작성할 수 있다. 2. 네이밍 규칙을 사용하면 따라오는 효과 가독성 향상 : 의미 있는 단어를 사용해 코드의 의도를 쉽게 알 수 있고, 유지보수나 협업에 도움이 된다. 일관성 유지 : 일관된 네이밍 규칙을 따르면 코드가 전체적으로 일관성 있어 다양한 파일과 모듈 간의 이동과 이해를 용이하게 만든다. 버그 감소 : 명확한 이름을 사용하면 변수나 함수의 역할을 파악하기 쉬워지므로 실수나 버그 발생 가능성이 줄어든다. 3. 자바 네이밍 규칙 1. 공통 규칙 대소문자가 구분되어야 하고 길이에 제한이 없다. 예약어는 사용하면 안된다.(ex : class, import, char, break 등···) 숫자로 시작하면 안된다. 특수문자는 \u0026lsquo;_\u0026rsquo;(언더바)와 \u0026lsquo;$\u0026rsquo;(달러 기호)만 사용 가능하다. 파스칼 표기법과 카멜 표기법을 사용한다. 파스칼 표기법 : 모든 단어의 첫 번째 문자는 대문자이며 나머지는 소문자로 작성한다. (ex : PasclaCase ) 카멜 표기법 : 최초로 사용되는 단어는 모두 소문자로 작성하고 그 이후 첫번째 문자는 대문자 나머지는 소문자로 작성한다. (ex : camelCase) 반의어는 반드시 대응하는 개념으로 사용해야 한다. (반의어 종류 보러가기) 2. 패키지 명명 규칙 소문자로 시작(모든 소문자를 권장) 가급적 한던어 사용 권장 표준 패턴 권장(com.(회사명 / 팀 이름).프로젝트명.상위패키지.하위패키지.클래스) ex : com.choi.management.user.controller 3. 클래스 명명 규칙 파스칼 표기법 사용 명사 시작 ex : UserController 4. 인터페이스 명명 규칙 클래스랑 비슷한 명명 규칙을 갖고있다. 복수형 개념인 경우 복수형을 작성해준다. 축약어, 약어는 가급적 작성하지 않고 의미있는 단어로만 작성한다. 특별한 접두사나 접미사를 사용하지 않고 파스칼 표기법 사용 형용사 사용 할 수 있다.(Runnable, Remote 등…) ex : ConvertUserToMemberHandler 5. 인터페이스 명명 규칙 클래스랑 비슷한 명명 규칙을 갖고있다. 복수형 개념인 경우 복수형을 작성해준다. 축약어, 약어는 가급적 작성하지 않고 의미있는 단어로만 작성한다. 특별한 접두사나 접미사를 사용하지 않고 파스칼 표기법 사용 형용사 사용(Runnable, Remote 등···) ex : ConvertUserToMemberHandler 6. 메서드 명명 규칙 카멜 표기법 사용한다. 동사로 시작한다. ex : sendMessage(String message) 7. 변수 명명 규칙 카멜 표기법 사용한다. 명확한 이름으로 작성한다. boolean으로 가져올 때는 앞에 is를 붙인다. ex : userName, isChecked 8. 상수 명명 규칙 전부 대문자료 표기한다. 스네이크 케이스를 사용한다.(Snake Case : 단어와 단어 사이를 언더바(\u0026rsquo;_\u0026rsquo;)로 구분) ex : PI, MAX_COUNT 1 2 3 4 5 6 7 8 9 10 public class Score() { // final 변수 선언과 초기화(최대 점수 : 100점) // 만약 초기화를 비어둔다면 추후에 초기화가 불가능 하다...(반드시 선언과 동시에 초기화 해주자!!) // 자바 명명 규칙은 나중에 게시물로 상세하게 작성해보겠다! 오늘 사용하는 상수는 대문자로! 단어와 단어 사이는 언더바를 이용한다! final int MAX_SCORE = 100; // 컴파일 에러가 발생 MAX_SCORE = 60; } final 메서드 오버라이딩 방지 안정성 확보(의도하지 않은 동작 변경 방지, 일관성 유지) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 final class Exam { // 시험의 최대 점수는 final로 선언하고 name은 변수로 선언 private final int MAX_SCORE = 100; private String name; // 이름 입력 public setName(String name) { this.name = name; } // 이름 가져오기 public String getName() { return name; } // 최대 점수 가져오기 public final String getMaxScore() { return MAX_SCORE; } } class MathExam extends Exam { // 이름 가져오기 메서드 오버라이딩 가능 public String getName() { System.out.println(\u0026#34;이름 : \u0026#34; + name); return name; } // 컴파일 에러 발생(최대 점수 가져오기 메서드를 오버라이딩 불가) public final String getMaxScore() { // ... } } final 클래스 상속이 불가능 메서드 오버라이딩이 불가능 해당 클래스를 변경하지 못하기 때문에 보안성 및 안정성이 강화 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 final class Exam { // 시험의 최대 점수는 final로 선언하고 name은 변수로 선언 private final int MAX_SCORE = 100; private String name; // 이름 입력 public setName(String name) {스 this.name = name; } // 이름 가져오기 public String getName() { return name; } // 최대 점수 가져오기 public String getMaxScore() { return MAX_SCORE; } } // 아래의 코드는 컴파일 에러 발생 class MathExam extends Exam { // ... } 반의어 돌아가기(자바 네이밍 공통 규칙 보러가기)\nget / set : 가져오다. / 할당하다.\n(ex : getAge() / setAge() )\nadd / delete : 추가하다. / 제거하다.\n(ex : addUser() / deleteUser() )\ninsert / delete : 삽입 / 삭제\n(ex : insertUser() / deleteUser() )\nmin / max : 최소 / 최대\n(ex : minCnt() / maxCnt() )\nshow / hide : 보이다 / 숨기다\n(ex : showMove() / hideMove() )\nstart / stop : 시동 / 정지\n(ex : startMethod() / stopMethod() )\nsuspend / resume : 일시 정지 / 재개하다\n(ex : suspendMove() / resumeMove() )\nincrement / decrement : 증가 / 감소\n(ex : incrementViews() / decrementViews() )\ncreate / destroy : 창조하다. / 파괴하다.\n(ex : createMap() / destroyMap() )\nnext / previous : 다음 / 이전\n(ex : nextUser() / previousUser() )\nopen / close : 열다 / 닫다\n(ex : openFile() / closeFile() )\n포스트 작성 시 참고한 링크 자바 네이밍 규칙 - 1 자바 네이밍 규칙 - 2 ","date":"2023-08-19T16:03:49+09:00","permalink":"https://choiseungwoo98.github.io/p/java-%EC%9E%90%EB%B0%94-%EB%84%A4%EC%9D%B4%EB%B0%8D-%EA%B7%9C%EC%B9%99java-naming-convention/","title":"[Java] 자바 네이밍 규칙(Java Naming Convention)"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다.\n오늘은 여러가지 질문 중 final에 대해 알아보고자 한다.\njava에서 final 키워드란 뭘까? 1. final 의미 자바에서 final은 변수, 메서드, 클래스에 사용되는 키워드로서 불변성을 나타낸다. final로 선언된 요소는 한번 초가화하면 그 값을 변경할 수 없다. 예를 들면 정보처리기사라는 시험의 점수는 고정되어 있다! 시험을 보는 사람마다 점수가 다르게 선정된다면 혼란을 야기할듯.. 다만, 시험보는 사람의 수험번호와 같은 경우 모든 사람이 다를 것이다. 이와 같은 경우 각각의 점수를 final로 이름을 변수로 선언하는 것이 바람직하다! 2. final 종류 final 변수 값 변경 불가능 컴파일 시간 상수(final 변수는 컴파일 시간에 값을 결정하므로, 값을 바로 인라인하여 코드 삽입 가능) 인스턴스와 정적 변수에 적용 가능 1 2 3 4 5 6 7 8 9 10 public class Score() { // final 변수 선언과 초기화(최대 점수 : 100점) // 만약 초기화를 비어둔다면 추후에 초기화가 불가능 하다...(반드시 선언과 동시에 초기화 해주자!!) // 자바 명명 규칙은 나중에 게시물로 상세하게 작성해보겠다! 오늘 사용하는 상수는 대문자로! 단어와 단어 사이는 언더바를 이용한다! final int MAX_SCORE = 100; // 컴파일 에러가 발생 MAX_SCORE = 60; } final 메서드 오버라이딩 방지 안정성 확보(의도하지 않은 동작 변경 방지, 일관성 유지) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 final class Exam { // 시험의 최대 점수는 final로 선언하고 name은 변수로 선언 private final int MAX_SCORE = 100; private String name; // 이름 입력 public setName(String name) { this.name = name; } // 이름 가져오기 public String getName() { return name; } // 최대 점수 가져오기 public final String getMaxScore() { return MAX_SCORE; } } class MathExam extends Exam { // 이름 가져오기 메서드 오버라이딩 가능 public String getName() { System.out.println(\u0026#34;이름 : \u0026#34; + name); return name; } // 컴파일 에러 발생(최대 점수 가져오기 메서드를 오버라이딩 불가) public final String getMaxScore() { // ... } } final 클래스 상속이 불가능 메서드 오버라이딩이 불가능 해당 클래스를 변경하지 못하기 때문에 보안성 및 안정성이 강화 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 final class Exam { // 시험의 최대 점수는 final로 선언하고 name은 변수로 선언 private final int MAX_SCORE = 100; private String name; // 이름 입력 public setName(String name) { this.name = name; } // 이름 가져오기 public String getName() { return name; } // 최대 점수 가져오기 public String getMaxScore() { return MAX_SCORE; } } // 아래의 코드는 컴파일 에러 발생 class MathExam extends Exam { // ... } 포스트 작성 시 참고한 링크 자바에서 final에 대한 이해 ","date":"2023-07-22T18:37:42+09:00","permalink":"https://choiseungwoo98.github.io/p/java-final-%EC%82%AC%EC%9A%A9%EB%B2%95/","title":"[Java] final 사용법"},{"content":" 커리어리라는 어플을 보다가 주니어 자바 개발자를 위한 100가지 질문을 보게 되었다.\n8개월 동안 회사에서 프로젝트를 여러개 진행하면서 다양한 기술을 사용해봤다.\n하지만 기초 및 이론 공부는 굉장히 소홀했었다..\n기초가 단단하지 않으면 나의 개발 스펙트럼도 짧아 질것 같아서 하나하나 정리해보려 한다.\n요즘 다시 괜찮아져서 블로그도 다시 시작\u0026hellip; 화이팅..!\n들어가기 앞서 오늘은 자바 플랫폼에 대해 알아보고자 한다. JDK, JRE, JVM은 자바 플랫폼의 3대 구성요소이다. 오늘은 JDK, JRE, JVM에 추가로 JIT까지 알아보고자 한다. 이미지를 먼저 확인 후 본격적으로 들어가보자..! JDK와 JRE 그리고 JVM JDK(Java Development Kit : 자바 개발 키트) 1. JDK는 무엇일까? Java를 사용하기 위해 모든 기능을 갖춘 SDK(Software Development Kit) JRE를 포함한 컴파일러(javac)와 jdb, javadoc 같은 도구를 포함 즉, 프로그램을 생성하고 컴파일 할 수 있다. 2. JDK 종류 Java SE(Java Standard Edition) 표준 에디션의 자바 플랫폼, 자바 언어의 핵심 기능 제공 주요패키지 java.lang.*, java.io.*, java.util.*, java.awt.*, java.rmi.*, java.net.* Java EE(Java Enterprise Edition) Java SE에 웹 애플리케이션 서버에서 동작하는 기능을 추가한 플랫폼 즉, 서버측 개발을 하기 위해 필요(JSP, Servlet, JDBC 등 기업용 애플리케이션 개발에 필요한 다양한 플랫폼) 이 스펙에 따라 제품을 구현한 것이 WAS로 부름 Java ME(Java Micro Edition) 임베디드 기기들에서 구동되기 위한 환경을 제공하는 API를 모아둔 플랫폼 제한된 자원을 가진 휴대전화, PDA(소형 전자 기기) 등에서 Java 프로그래밍 언어를 지원하기 위해 만든 플랫폼 3. JDK 기본 도구 javac : 자바 컴파일러(자바 소스파일 =\u0026gt; 바이트 코드) java : javac가 만든 클래스 파일을 해석 및 실행 jdb : 자바 디버깅 툴 JRE(Java Runtime Environment : 자바 런타임 환경) 1. JRE는 무엇일까? 자바로 만든 애플리케이션을 실행할 수 있는 런타임 환경 구축 JVM과 핵심 라이브러리 및 자바 런타임 환경에서 사용하는 프로퍼티 세팅이나 리소스 파일 제공 JDK와 달리 개발하는데 필요한 툴은 제공되지 않는다. 클래스 로더, 클래스 라이브러리를 통해 작성한 코드를 라이브러리와 결합 후 JVM에 넘겨 실행 JRE는 특별한 기능을 수행하기 보단 JVM이 원할하게 잘 작동할 수 있도록 환경에 맞춰주는 역할 2. JRE 구성요소 JVM(Java Virtual Machine) : 자바 가상 머신으로 아래 따로 다루겠습니다. Java Class Libraries : 개발하면서 자주 사용하는 여러 유용한 기능들을 모아놓은 클래스 집합 라이브러리 Java Class Loader : JVM이 동작하다가 클래스 파일을 참조하는 순간 동적으로 읽어 JVM에 링크되고 메모리에 로딩하는 역할 JVM(Java Virtual Machine : 자바 가상 머신) 1. JVM은 무엇일까? 자바 프로그램이 어느 기기, 운영체제 상에서도 실행될 수 있도록 만듦(WORA : 한 번 쓰고 모든 곳에서 실행한다) 메모리를 효율적으로 관리 및 최적화(Garbage Collection) JVM은 단독으로 사용이 불가, 최소 배포 단위는 JRE이다. 2. 가비지 컬렉션(Garbage Collection)? JVM이 메모리를 관리하는 프로세스 사용하지 않는 메모리를 지속적으로 찾아 제거해 효육적인 메모리 관리 가비지 컬렉션 JIT(Just In Time Compilation) 방식 1. JIT는 무엇일까? 프로그램을 실제 실행하는 시점에 기계어로 번역하는 컴파일 기법 2. 컴파일 기법 컴파일 기법에는 인터프리터 방식와 컴파일러 방식로 나뉨 인터프리터 방식는 코드를 한 줄씩 중간 코드인 바이트 코드로 변환 후 실행 컴파일링 방식는 코드 실행 전, 소스 코드를 한번에 기계어로 변환 후 실행 컴파일 기법 3. Java 컴파일 기법 자바는 컴파일러 방식을 사용한다 Java Compiler를 통해 Byte Code로 변환되고 다시 기계어로 변환된다. 이 과정이 있기 때문에 느리다 평가가 존재한다. 이러한 단점을 극복하기 위해 JIT 방식이 채택되었다. 4. JIT 방식 자주 쓸만한 코드들을 기계어로 변환 시켜놓고 저장 후 이미 변환된 기계어 코드를 재사용하는 방식 포스트 작성 시 참고한 링크 JDK(Java Development Kit) JRE(Java Development Kit) JVM(Java Virtual Machine) JIT(Just In Time Compilation) ","date":"2023-07-21T19:29:42+09:00","permalink":"https://choiseungwoo98.github.io/p/java-jdk%EC%99%80-jre%EC%9D%98-%EC%B0%A8%EC%9D%B4-%EA%B7%B8%EB%A6%AC%EA%B3%A0-jit-jvm/","title":"[Java] JDK와 JRE의 차이 그리고 JIT, JVM"},{"content":" 일을 하던 중 프로그래스 바와 같은 작업의 완료 타이밍을 알 수 있는 방법이 있을까?\n같은 고민을 하다가 WebSocket을 알게 되었고 그 과정을 글로 작성해보려고 한다.\nWeb Socket을 사용한 코드 게시물은 추후에 작성하겠습니다!! 아래 코드는 첨부했습니다!\n포스트 작성 시 참고한 링크 코드 ","date":"2023-05-06T19:29:42+09:00","permalink":"https://choiseungwoo98.github.io/p/java-spring-boot-websocket--stomp-%EC%82%AC%EC%9A%A9%ED%95%98%EA%B8%B0/","title":"[Java] Spring Boot, Websocket + STOMP 사용하기"},{"content":" 일을 하던 중 프로그래스 바와 같은 작업의 완료 타이밍을 알 수 있는 방법이 있을까?\n같은 고민을 하다가 WebSocket을 알게 되었고 그 과정을 글로 작성해보려고 한다.\n서버에서 클라이언트로 이벤트를 보내는 4가지 방법 1. Polling 클라이언트가 평벙한 http request를 서버로 계속 날려서 이벤트 내용을 받는 방법 가장 쉬운 방법이지만 클라이언트가 지속적으로 request를 보내야 하기 때문에 클라이언트가 많아 질 수록 서버 부담이 급증 실시간으로 정보를 응답 받는 것이 아닌 반복해서 request를 보내는 사이에 바뀐 내용을 받아오는 방식 http 오버헤드가 발생한다는 큰 단점. 하지만 일정 시간 갱신되는 서버 데이터의 경우 유용. Polling 방식 2. Long Polling 서버 측에서 접속을 열어두는 시간을 길게하는 빙식 클라이언트가 서버에 http request를 날리면 서버에서 응답해야할 이벤트가 발생하면 그 순간 응답을 하는 방식 응답을 받은 클라이언트는 바로 http request를 날려 다음 이벤트 대기 polling 방식보다 서버 부담은 줄지만 이벤트 발생 간격이 좁다면 polling이랑 다르지 않음 다수의 클라이언트에게 동시에 이벤트가 발생될 경우 클라이언트가 바로 접속을 시도하면서 서버 부담이 급증 Long Polling 방식 3. WebSocket 양방향 채널을 이용해 채팅방 처럼 양방향 통신하는 방식 기존 http요청 응답 방식은 요청한 클라이언트에 응답만 가능했지만, ws 프로토콜을 통해 웹소켓 포트에 접속해 있는 모든 클라이언트에 이벤트 응답 가능 최초 접속이 일반 http request를 통해 handshaeking 과정을 통해 이루어 지기 때문에, 기존 80, 443포트로 접속하므로 추가 방화벽을 열지 않아도 가능 http 규격인 CORS 적용이나 인증등의 과정을 기존과 동일하다는 장점 단, websocket 프로토콜을 처리하기 위한 전이중 연결과 새로운 웹소켓 서버 필요 WebSocket 방식 4. SSE(Server-Sent-Events) HTML5 표준안이며 어느정도 웹소켓의 역할을 하면서 가벼움 WebSocket과 같이 양방향이 아닌 server -\u0026gt; client 단방향이기 때문에 서버에서 이벤트나 메시지를 client로 push 하는 작업에 유용 양방향이 아니라 요청 시 ajax로 쉽게 이용 재접속 처리 같은 대부분이 저수준 처리가 자동 지원 IE는 기본 미지원이지만, polyFill을 이용할 경우 IE를 포함한 크로스브라우징 가능 SSE(Server-Sent Event) 방식 WebSocket + Stomp를 이용하여 서버와 양방향 통신 다음 게시물은 WebSocket과 Stomp를 이용하여 서버와 양방향 통신을 하는 방법에 대해 스몰 모듈 프로젝트를 만들고자 한다.\n포스트 작성 시 참고한 링크 서버에서 클라이언트로 이벤트를 보내는 4가지 방법 ","date":"2023-05-06T19:29:42+09:00","permalink":"https://choiseungwoo98.github.io/p/java-%EC%84%9C%EB%B2%84%EC%97%90%EC%84%9C-%ED%81%B4%EB%9D%BC%EC%9D%B4%EC%96%B8%ED%8A%B8%EB%A1%9C-%EC%9D%B4%EB%B2%A4%ED%8A%B8%EB%A5%BC-%EB%B3%B4%EB%82%B4%EB%8A%94-4%EA%B0%80%EC%A7%80-%EB%B0%A9%EB%B2%95/","title":"[Java] 서버에서 클라이언트로 이벤트를 보내는 4가지 방법"},{"content":" Mysql을 사용하여 프로젝트를 하나 진행 중이었습니다.\n해당 프로젝트가 끝나고 새로운 프로젝트를 진행하게 되었는데,\n새로운 프로젝트에서는 MariaDB를 사용해야하는 상황이었고, Mysql과 MariaDB는 서로 프로토콜, 프로세스 명, 명령어 등을 쉐어하고 있다고 알려져 있어 MySql이 설치되어있는 상황에서 MariaDB를 다운하면 충돌이 발생하고\nMySql을 지우고 다운받을 수 없는 상황이라 동시에 사용하기 위해 Docker로 설치해여 사용하려 합니다.\nDocker?? 컨테이너 기반의 오픈소스 가상화 플랫폼\n다양한 프로그램, 실행 환경을 컨테이너로 추상화하고 동일한 인터페이스를 제공하여 프로그램 배포 및 관리를 단순화 한다. 컨테이너 엔진으로 리눅스 커널 기능을 사용하여 운영체제 위에 컨테이너를 만들고, 데몬으로 실행된다. Linux 커널의 도커 엔진 컨테이너?? 호스트 OS상에 논리적인 구획(컨테이너)을 만들고, 어플리케이션을 작동시키기 위해\n필요한 라이브러리나 어플리케이션 등을 하나로 모아, 마치 별도의 서버인 것처럼 사용할 수 있게 만든 것 컨테이너는 오버헤드가 적기 때문에 가볍고 고속으로 작동하는 것이 특징입니다. Docker Image?? Docker에서 image는 파일로 어플리케이션 실행에 필요한 독립적인 환경을 포함한 일종의 템플릿 소스 코드, 라이브러리, 종속성, 도구 및 응용 프로그램을 실행하는데 필요한 기타 파일을 포함하는 불변 파일 읽기 전용이며 스냅샷 이라고도 부르고 이러한 일관성은 개발자에게 안정적이고 균일한 조건에서 테스트 할 수 있도록 함. Docker Install brew로 설치 virtualbox, vargrant 등 가상머신 위에 도커를 띄우는 작업 필요 compose, machine등 추가 설치 필요 서버 실행시 호스트 OS에서 서버 접근시 포트 포워딩 필요 brew cask로 설치 brew cask 는 Docker Desktop on Mac 도커를 설치해주며, docker-compose, docker-machine을 같이 설치 해줌 맥 OS에서 띄우기 때문에 가상 머신에서 포트 포워딩을 할 필요 없음 1 2 3 4 5 # 먼저 cask 먼저 설치 $ brew install cask # Docker Install $ brew install --cask docker 위와 같이 입력하면 docker는 정상적으로 잘 다운된다!\nMariaDB Install 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # Docker Image 받기 $ docker pull mariadb # mariadb 확인 $ docker images # MariaDB 컨테이너 실행 # (1) docker run : docker image에서 container를 생성 # (2) –name maria-db : maria-db라는 이름을 가진 컨테이너 생성 # (3) -p 3307:3306 : 해당 컨테이너의 포트 forwarding에 대해 inbound는 3307로 하고, # outbound는 3306으로 설정한다. # 외부에서 접속 시 3307 포트를 사용하여 컨테이너에 정보를 전달하면, 컨테이너는 내부적으로 3306 포트를 # 사용하여 처리하고 정보를 외부로 보낸다. mySQL에서도 MariaDB와 동일하게 3306 포트를 사용하기 때문. # (4) -e : 컨테이너 내 변수 설정 # (5) MYSQL_ROOT_PASSWORD=”암호” : ROOT 암호 설정 # (6) -d mariadb : mariadb라는 이미지에서 분리하여 컨테이너 생성 # (7) --lower_case_table_names=1 : 대소문자 구분을 제거해준다. $ docker run --name mariadb -p 3307:3306 -e MYSQL_ROOT_PASSWORD=1234 -d mariadb --lower_case_table_names=1 # 실행 중인 도커 확인 $ docker ps # 도커 명령어를 통해 DB 접속 $ docker exec -it mariadb mysql -u root -p 여기까지 잘 하셨으면 이제 local에서 세팅 가능합니다. 저는 DataGrip을 통해 연결해보도록 하겠습니다.\nDataGrip 연결 아래 순서대로 진행하면 연결 가능하다!!!\n포스트 작성 시 참고한 링크 도커란?\nDocker Install\nMariaDB Install\n","date":"2023-03-17T01:03:57+09:00","permalink":"https://choiseungwoo98.github.io/p/docker-docker%EB%8A%94-%EB%AD%98%EA%B9%8C/","title":"[Docker] Docker는 뭘까?"},{"content":" workflow는 어떤 것이 있고 어떤 방법론이 있는지 조사해보자고 마음을 먹어 작성하게되었다.\nWorkFlow?? Git은 브랜치로 작업을 관리한다.\n팀에서 브랜치를 어떻게 사용할 지에 대한 규칙을 Workflow라고 한다.\nGit에서 대표적인 Workflow는 Git flow, Github flow, Gitlab flow가 있다.\nGit flow 브랜치의 역할이 명확하고 대규모 프로젝트에 적합.\n2개의 메인 브랜치, 3개의 보조 브랜치로 나뉨.\nMain Branch\nmaster 제품으로 출시하는 브랜치 실제 배포 중이 상용 버전 develop 다음 출시 버전을 개발하는 브랜치 실제 작동 중인 버전의 다음 버전을 개발하기 위한 메인 스트림 Serve Branch\nfeature 기능을 개발하는 브랜치 develop에서 뻗어 나와 develop으로 합쳐짐 실제 개발을 할때 가장 많이 쓰이는 브랜치 기능 별 브랜치 생성 후 개발 완료 시 develop 병합 자유로운 브랜치명, 서버에 올리지 않고 local에서 작업 release 새로운 버전을 배포하기 위한 브랜치(QA 용도) develop에서 뻗어나와 develop으로 합쳐지거나 배포 준비 완료 시 master로 합쳐짐 주로 버그를 수정하는 디버깅만 커밋 release-* 라는 이름을 사용 master에 병합했다면 develop에도 병합해 내용 일치시킴 hotfix 상용 제품에서 버그 발생 시 처리하는 브랜치 master에서 뻗어 나와 버그 수정 후 master와 develop으로 병합 버그 픽스를 위한 브랜치로 다버깅만 커밋하며, 보통 일회성 사용 작업 과정\n개인 작업은 develop에서 feature 브랜치를 따서 작업한다. 개인 작업이 끝나면 develop에 병합한다. develop브랜치에서 배포 준비가 끝나면 release 브랜치로 분할한다. release 브랜치에서 디버깅하고 문제가 없으면 master와 develop 브랜치에 합친다. master브랜치를 배포한다. 만약 배포 버전에서 문제가 생겨 급하게 수정해야 하면 hotfix 브랜치를 따서 작업한다. hotfix에서 버그픽스가 끝나면 master와 develop에 합친다. Git flow Github flow 하나의 메인 브랜치인 master 브랜치를 중점으로 운용하며 pull request을 활용한 방식 master 브랜치는 항상 최신 버전 유지 및 안정적이어야 함 브랜치의 용도가 명확하게 분류되어 있지 않아 브랜치 생성 시 브랜치 명을 명확하게 작성 일반적으로 feature 브랜치의 작업은 local 저장소가 아닌 원격 저장소에 저장\n작업 과정\n개인 작업은 feature 브랜치에서 작업하며 작업이 끝나면 pull request를 생성한다. pull request에서 코드 리뷰 후에 문제가 없으면 master로 병합한다. master에 병합하면 바로 배포 작업을 수행한다. (CI 자동화 권장) Github flow Gitlab flow master, develop(production) 2개의 메인 브랜치로 관리\n항상 최신 버전의 버전을 유지하지 않아도 됨\n배포 버전과 개발 버전을 따로 둘 수 있다는 장점\ndevelop 브랜치는 github flow의 develop브랜치와 같은 역할을 한다. master 브랜치는 배포 버전이다. 작업 과정\n개인 개발은 feature 브랜치에서 작업하고 완료 시 merge develop 브랜치가 배포되기 적합하다고 판단되면 master브랜치로 merge한다. Gitlab flow Centralized Workflow 단일 중앙 저장소를 사용하며 master 브랜치 하나만 사용\n팀 구성원들은 중앙 저장소를 복제하여 로컬 저장소를 만들고, 변경 내용을 커밋하고 언제든 중앙 저장소와 동기화 진행\n중앙 저장소의 커밋이 기준이 되므로, 변경 사항을 푸시할 때, 저장소의 커밋과 충돌난다면 Git은 푸시를 거부\n이 때 중앙 저장소의 변경 내용을 가져와 자신의 변경 내용과 병합하거나 재배열하여 충돌 해결 후 푸시\n작업 과정\n중앙 저장소를 클론하려 로컬 저장소 생성 커밋 이력을 중앙 저장소에 푸시 다른 개발자가 중앙 저장소로 푸시할 때 최신 커밋을 반영되어 있지 않으면 푸시 거부 push 할 때는 항상 최신 커밋 이력을 포함해서 올려야함 Centralized Workflow 특징\nGit에 특징인 분산 버전 관리의 이점을 사용할 수 없지만 최소한의 명령어로 협업 가능\nCentralized Workflow Feature Branch Workflow 기능 별 브랜치를 만들어 작업 하는 것\nmaster 브랜치에 손대지 않기 때문에 다른 기능 브랜치를 얼마든지 올려도 된다. 이는 로컬 저장소 백업 역할 수행\nmaster 브랜치는 항상 버그 프리 상태로 유지하며, 병합 시 권한을 가진 사용자가 pull request 적용\n작업 과정\n중앙 저장소를 클론한 로컬 저장소에 작업 브랜치 생성 작업 브랜치에서 작업 후 커밋 생성 및 원격 저장소로 푸시(브랜치와 같이) pull requst를 남겨 팀에게 작업 완료 사실을 알림 담당자가 작업 내용을 검증하고 수정이 필요하다 판단되면 해당 내역을 알려줌 해당 부분을 수정 후 푸시(pr은 다시 올리지 않아도 수정 내용이 전부 표시) 담당자가 검증 후 pr을 수용하기로 결정 되었다면 병합 진행(병함은 아무나 가능) Feature Branch Workflow 특징\n브랜치를 이용하면 안전하게 새 기능을 개발 할 수 있을 뿐만 아니라,\npull request를 이용해서 브랜치에 대한 팀 구성원들의 토론 참여를 이끌어냄\npull request는 코드 리뷰의 시작점\n코드 리뷰를 진행하면 컨벤션을 맞출 수 있음\n개발 중 막히는 부분이 pr을 통해 의견을 주고 받아 팀 구성원의 도움을 받을 수 있음. 큰 규모의 프로젝트를 관리할 때는 Gitflow Workflow를 사용해 기능 개발, 릴리스, 유지보수를 위해 좀 더 엄격한 워크플로우를 유지.\nFeature Branch Workflow Forking Workflow 하나의 중앙 저장소를 이용하는 것이 아니라, 개개인마다 서로 다른 원격 저장소를 운영\n자신의 원격 저장소에 푸시하고 그 내용을 공식 저장소의 프로젝트 관리자에게 풀 리퀘스트를 보냄\n관리자는 공식 저장소에 푸시 권한을 주지 않고도 다른 개발자의 커밋을 수용 프로젝트와 직접 관련이 없는 제 3자뿐만 아니라, 아주 큰 규모의 분산된 팀에서도 안전하게 협업하기에 좋은 방법.\n특히, 오픈소스 프로젝트에서 많이 사용하는 방식\n작업 과정\n공식 저장소를 fork해 나의 원격 저장소 생성 다른 개발자들은 나의 원격 저장소에 푸시 할 수 없음. fork한 원격 저장소를 clone해 작업 수행 내 원격 저장소에 push하고 작업분을 반영 할 수 있는 프로젝트 관리자에게 pr을 보냄. Forking Workflow 특징\n다른 워크플로우에서는 공식 저장소에 브랜치를 푸시해서 팀 구성원들이 공유했다면, Forking Workflow에서는 나의 브랜치를 다른 참여자들이 자신의 로컬 저장소로 내려 받아 참고하고 병합\nForking Workflow 포스트 작성 시 참고한 링크 Git Workflow 다양한 Workflow centralized-workflow 이미지 feature-branch-workflow 이미지 forking-workflow ","date":"2023-03-05T04:39:34+09:00","permalink":"https://choiseungwoo98.github.io/p/git-workflow-%EC%9E%91%EC%97%85-%EB%B0%A9%EC%8B%9D/","title":"[Git] Workflow? 작업 방식?"},{"content":" 프로그래밍을 공부 했을 시절 분기되었던 브랜치를 합치는 것 작업을 merge로 만 수행했었다.\n현업에 들어오고 나서 git history가 엉망이 되어가는 것을 직접 목격하였다\u0026hellip;\n어떻게 해야 history를 잘 관리 할 수 있는지 궁금하였고 사수의 도움으로 rebase하는 것을 알게 되었다.\nrebase 를 알고 사용하고 있지만 merge와 rebase의 차이점을 명확하게 알고 싶어 찾아보았다.\n들어가기 앞서 merge와 rebase의 차이를 알아보기 전에 이것들은 어떤 상황에서 사용하며 사용하면 어떤 일이 일어나는지 부터 간단하게 알아보고자 한다.\nGit이란?\n형상 관리 도구 중 하나이며 소스코드를 효과적으로 관리할 수 있게 해주는 공개 소프트웨어이다.\nbranch란?\nSoftware 개발 시 다양한 개발자들이 동일한 프로젝트 위에서 개발, 유지보수 등의 업무를 하는 경우가 많다.\n이때 하나의 프로젝트 에서 동시에 작업하게 되면 여러가지 문제가 발생한다.\n이 것을 해결하기 위해 각각 완전히 독립된 브랜치 생성하여 동시에 코드 개발 및 수정 할 수 있게 도와준다.\nmerge? rebase? merge는 분기된 branch를 다른 branch로 합치는 과정이고\nrebase는 branch의 base를 옮긴다는 개념의 차이가 있다.\nmerge와 rebase의 특징 merge\n병합을 하면 합쳐진 브랜치의 커밋 메시지가 중복으로 쌓임. 커밋 순서를 변경되지 않음. 존재하는 브랜치가 변경되지 않음. 새로운 merge commit을 생성. git merge rebase\n병합을 하면 브랜치의 커밋 메시지가 시간 순서대로 합침. 히스토리를 깔끔하게 유지하기 위해 사용. 분기된 브랜치를 마스터 브랜치 끝에 위치 시켜, master 브랜치를 재배치(rebase) 하는 것을 말함. 즉, rebase는 어떤 특정 브랜치의 커밋 이력을 base로 재정렬되면서 해쉬 ID가 바뀜 git rebase rebase를 사용하는 이유 하나의 프로젝트의 많은 개발자들이 활발하게 작업을 진행하게 되면 많은 브랜치가 생기고\nmaster브랜치로 merge만 한다면 엄청나게 복잡한 git history를 볼 수 있을 것이다.\nrebase를 하여 작업 순서대로 history를 관리하고 불필요한 병합 커밋을 제거할 수 있다.\nmerge와 rebase history 비교 rebase 사용 시 유의점 여러 사람이 사용하고 활발하게 커밋이 일어나는 브랜치라고 한다면, Rebase를 하는 것은 자칫 위험할 수 있습니다.\n왜냐하면 파생된 브랜치에서 이미 새로운 커밋이 발생하고 작업이 기록되고 있는데\n이전 기준 브랜치로 base를 변경해버리면 파생브랜치로 작업하고 있던 작업자들의 커밋 히스토리가 변경되어 버리기 때문입니다. 각 작업자들은 자신의 커밋을 다시 반영하거나 재작업을 해야 할 수도 있습니다.\n따라서 혼자 작업하는 브랜치나 작업하는 사람이 적어 문제상황이 발생할 확률이 적은 경우에만 주의깊게 사용해야 합니다.\n포스트 작성 시 참고한 링크 merge와 rebase 차이 rebase 사용 시 유의사항 ","date":"2023-03-05T04:30:49+09:00","permalink":"https://choiseungwoo98.github.io/p/git-merge%EC%99%80-rebase-%EC%B0%A8%EC%9D%B4/","title":"[Git] Merge와 Rebase 차이"},{"content":"브랜치?? 여러 개발자들이 동시에 다양한 작업을 할 수 있게 만들어 주는 기능이 바로 브랜치(Branch) 이다.\n각자 독립적인 작업 영역(저장소) 안에서 마음대로 소스코드를 변경할 수 있다.\n이렇게 분리된 작업 영역에서 변경된 내용은 나중에 원래의 버전과 비교해서 하나의 새로운 버전으로 만들어 낼 수 있다.\n브랜치 사용법 메인 브랜치에서 자신의 작업 전용 브랜치를 만듦 각자 작업을 진행한 후, 작업이 끝난 사람은 메인 브랜치에 자신의 브랜치의 변경 사항을 적용 다른 사람의 작업에 영향을 받지 않고 독립적으로 특정 작업을 수행하고 그 결과를 하나로 모음 브랜치로 그 작업의 기록을 중간 중간에 남기게 되므로 문제가 발생했을 경우 원인이 되는 작업을 찾아내거나 그에 따른 대책을 세우기 쉬워짐 Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 브랜치 생성 # git branch branchName $ git branch myWork-1 # 브랜치 이동 # switch 혹은 checkout 둘 다 가능 # git switch branchName $ git switch myWork-1 # 브랜치 생성 및 이동 # git checkout -b branch_name # git switch -c branch_name $ git switch -c myWork-2 # 현재 브랜치 확인 $ git branch # 브랜치 삭제 # git branch -d branchName $ git branch -d myWork-1 포스트 작성 시 참고한 링크 브랜치란? ","date":"2023-03-05T00:40:51+09:00","permalink":"https://choiseungwoo98.github.io/p/git-branch%EA%B0%80-%EC%9E%90%EC%84%B8%ED%9E%88-%EB%AD%98%EA%B9%8C/","title":"[Git] branch가 자세히 뭘까?"},{"content":" 현재 가장 많이 사용하고 있는 형상관리도구 git에 대해 공부를 하다가 문득 궁금한 것이 생겼다. Git은 형상관리 도구 중 하나인데 다른 형상관리도구랑 어떠한 차이가 있을까? 그래서 한번 각각의 형산관리 도구에 대해 알아보고 장단점은 무엇인지 알아보고자 한다.\n형상관리?? 소프트웨어 구성 관리(Software Configuration Management) 또는 형상관리는 소프트웨어의 변경사항을 체계적으로 추적하고 통제 하는 것 일반적으로 단순 버전관리 기반의 소프트웨어 운용을 좀 더 포괄적인 학술 분야의 형태로 넓히는 근간 소프트웨어의 소스 코드, 개발 환경, 빌드 구조 등 전반적인 환경 전반적인 내역에 대한 관리 체계를 정의 형상 관리는 포괄적인 개념, 통상적으로 버전관리, 소스관리 등으로 불립니다. 즉, 정보를 여러 버전을 관리하는 것\n변경관리 / 버전관리 / 형상관리 변경관리, 버전관리, 형상관리. 표면적인 의미로 보면 거의 비슷하지만 이들은 제어 및 지원 범위에서 차이가 있다.\n변경 관리 : 소스코드 변경 사항에 대한 관리 버전 관리 : 변경사항을 ‘버전’이란 개념을 통해 관리. 형상 관리 : 위의 개념을 포함해 프로젝트와 관련된 모든 변경사항을 관리. 포함관계를 포함하자면\n변경관리 ⊆ 버전관리 ⊆ 형상관리\n형상관리 3가지 버전 버전 관리 시스템? 형상관리 중에서 문서, 소스코드 등을 버전을 관리해주는 버전관리시스템이다.\n통상적으로 \u0026ldquo;형상관리 ≒ 버전관리\u0026rdquo; 임을 인지하고 접근하는 것이 이해하기 쉽다.\n버전 관리(형상 관리)를 위한 도구와 특징 CVS(Concurrent Version System)\n90년에 출시된 무료 서버-클라이언트 형상관리 시스템 파일 전체를 저장하는 것이 아니라 변경사항만을 저장 변경사항만 저장하기 때문에 용량을 적게 차지하지만 속도가 상대적으로 느림 Perforce(P4D)\n빠른 속도, 빠른 Merge가 가능하며 큰 리소스 관리에 좋음 유료이고 파일명이 바뀌면 히스토리 추적이 곤란 SVN (Subversion)\n형상관리/소스관리 툴의 일종 중앙관리만 지원 다른 사용자의 커밋과 엉키지 않으며, 커밋 실패 시 롤백 기능을 지원 Git\n분산형 버전관리 시스템 Repository의 완전한 복사본을 로컬에 저장할 수 있음 처리속도가 빠르지만 대용량 코드 관리에 부적절 가장 많이 사용하는 SVN과 Git 비교 SVN (Subversion)\nSVN은 보통 대부분의 기능을 완성해놓고 소스를 중앙 저장소에 commit commit의 이미 자체가 중앙 저장소에 해당 기능을 공개한다는 의미. 개발자가 자신만의 version history를 가질 수 없음. commit한 내용에 실수가 있을 시에 다른 개발자에게 바로 영향을 미치게 되는 단점도 있다. 저장소를 한개만 두는 것의 단점은 만약 데이터가 소실되었을때 복구가 어려움 Git\n개발자가 자신만의 commit history를 가질 수 있고, 개발자와 서버의 저장소는 독립적으로 관리가 가능. commit한 내용에 실수가 있더라도 이 바로 서버에 영향을 미치지 않음. 개발자는 commit 하다가 자신이 원하는 순간에 서버에 변경 내역(commit history)을 보낼 수 있음. 서버의 통합 관리자는 관리자가 원하는 순간에 각 개발자의 commit history를 가져올 수 있음. SVN과 Git 차이점 git은 로컬 저장소가 있으므로 네트워크에 접근할 필요가 없기 때문에 빠름. svn은 commit 하는 순간 저장소를 공유하는 모든 개발자들이 보게 된다. git은 내 로컬 저장소에서 마음껏 개발하고 정리하여 필요할 때 원격 저장소로 올림. git의 경우 원격 저장소 서버가 잠시 끊기더라도 버전 컨트롤이 가능 svn은 서버가 끊기는 순간 버전 컨트롤도 같이 끊김. 원격 저장소가 사라지면 svn은 복구 불가,\ngit은 로컬 저장소에 사본을 들고 있다면 복구 가능. svn은 저장소가 하나,\ngit은 로컬 저장소/원격 저장소로 저장소를 분산해서 관리 포스트 작성 시 참고한 링크 형상관리란 - 1 형상관리란 - 2 SVN, GIT 차이점 ","date":"2023-03-04T22:47:36+09:00","permalink":"https://choiseungwoo98.github.io/p/%ED%98%95%EC%83%81%EA%B4%80%EB%A6%AC-%ED%98%95%EC%83%81%EA%B4%80%EB%A6%AC%EB%9E%80-svn-git/","title":"[형상관리] 형상관리란 SVN? GIT?"},{"content":" 현업에서 일하기 시작한지 이제 3개월이 지나가고 있는 시점에 공부가 필요하다고 뼈저리게 느끼고 있습니다.\n직장에 다니기 전에 네이버 블로그를 통해 배운 내용을 정리하였지만\n조금 더 개발자스러운 블로그를 운영하고 싶다고 느껴 깃 블로그를 만들게 되었습니다.\n시작하기 앞서 운영체제는 MAC에서 제작하였습니다.\n블로그 플랫폼 선택 블로그를 쓰려고 마음먹고 나서 플랫폼이 뭐가 있는지 찾아보면서\n나한테 가장 잘 맞는 플랫폼은 뭐가 있을까?\n많은 고민을 하던 중 가장 많이 사용되고 있는듯(?)한 플랫폼 3가지를 비교해 보았다.\nJekyll\nRuby 기반 GitHub Page에 최적화되어 있음 현재 가장 대중적으로 사용하는 플랫폼 한글 레퍼런스가 제일 많음 빌드를 진행하는데 너무 오래걸림 Hexo\nJS(Node.js) 기반 한글 레퍼런스 꽤 있음 마크다운 문서로 만든 포스팅을 하는 방법이 간단 Git으로 포스트 버전관리 불가능(두가지 브랜치로 관리) Hugo\nGoLang 기반 빌드가 빠름 문서화 잘되어 있음 한글 레퍼런스가 거의 없음 Hugo!! 너로 정했다!! 기존 네이버 블로그를 작성하면서 테마가 이쁘고 커스텀 할 수있는 요소가 많은 블로그를 만들고 싶었다.\n테마가 마음에 들면서 기능이 많았으면 좋다고 생각했고 jekyll, hexo, hugo 중 빌드 속도가 제일 빠르고 Golang을 사용해 볼 수 있는 좋은 기회라는 생각이 들어 hugo를 선택하게 되었다.\n기본 환경 세팅 HomeBrew 설치\n터미널에 아래 코드를 입력해주면 다운로드가 완료 된다! 1 /bin/bash -c \u0026#34;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\u0026#34; Github 회원가입\n순서대로 진행해주면 가입된다! 또는 포털 사이트에서 github 입력 후 오른쪽 상단 sing-in을 누르면 위 링크와 같이 가입할 수 있다! Git Downloads 홈페이지에 방문해 운영체제에 맞게 다운받아준다! Golang 설치\n필자는 install을 통해 Golang을 다운했다\npakege-version : go1.20.1.darwin-amd64.pkg Hugo 설치 터미널에 다음과 같이 입력한다.\n1 2 3 4 5 6 7 8 9 10 11 # hugo 설치 $ brew install hugo # hugo version 확인 $ hugo version # 다음과 같이 뜨면 정상적으로 설치가 완료 된 것이다. hugo v0.110.0+extended darwin/amd64 BuildDate=unknown # 만약 brew link 에러가 발생한다면 brew에 권한을 설정해줘야함 $ sudo chown -R $(whoami) $(brew --prefix)/* Github repository 생성 2개의 레포지토리를 만들어야한다.\nex) blog, \u0026lt;username\u0026gt;.github.io\n내가 만든 레포지토리\nblog, choiseungWoo98.github.io\nHugo로 프로젝트 생성 내가 따로 프로젝트를 만들지 않아도 hugo가 알아서 만들어 준다.\n간편해..👍🏻\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # hugo 프로젝트 생성 $ hugo new site blog # 생성 완료되면 출력 문구 Congratulations! Your new Hugo site is created in /Users/username/folder/blog. Just a few more steps and you\u0026#39;re ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command. 2. Perhaps you want to add some content. You can add single files with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;. 3. Start the built-in live server via \u0026#34;hugo server\u0026#34;. Visit https://gohugo.io/ for quickstart guide and full documentation. 테마 설정 테마는 직접 만들 수 있다고 한다. 하지만 저는.. 기존 공개된 테마 중 가장 마음에 드는거로 사용하려한다.\n원하는 테마를 선택했다면 아까 다운받은 프로젝트에 적용시켜 주자!\n필자는 LoveIt테마를 사용하였다!!\n해당 사이트 이동 후 Download를 누르면 Github 페이지로 이동한다. 오른쪽 초록색 Code를 클릭 후 링크를 복사하자!\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # 현재 경로 확인 $ pwd # 프로젝트 경로로 이동 보통 유저 정보는 default로 설정되어 있다. 나갈때는 cd .. $ cd blog # 프로젝트 폴더에 들어왔는지 확인 $ pwd # 잘 들어왔으면 아래와 같이 출력된다. # /Users/\u0026lt;username\u0026gt;/blog # git 저장소로 사용하기 위한 git 명령어 $ git init # git branch 명을 변경하려면 사용해주면 된다 나는 master가 아닌 main으로 사용하고 있다. $ git branch -M main # 아까 사용하려고 했던 테마의 깃 주소를 복사해 아래와 같이 작성해주면 테마가 다운로드 된다. # git submodule add \u0026lt;복사한 테마 주소\u0026gt; themes/\u0026lt;테마 이름\u0026gt; $ git submodule add https://github.com/dillonzq/LoveIt.git themes/LoveIt # blog 폴더 내부에 있는 config.toml을 다운받은 테마에 맞게 수정해준다 # 기존에 config.toml # baseURL = \u0026#39;http://example.org/\u0026#39; # languageCode = \u0026#39;en-us\u0026#39; # title = \u0026#39;My New Hugo Site\u0026#39; # cp themes/\u0026lt;위에서 설정한 테마 이름\u0026gt;/exampleSite/config.toml config.toml $ cp themes/LoveIt/exampleSite/config.toml config.toml 이후 config.toml을 자신의 맞게 수정하면 된다. baseURL은 반드시 수정해야함!\n블로그 커스텀은 추후에 한번에 다루겠습니다!\n위에서 설정한 Repository name을 baseURL에 작성\nex) baseURL = \u0026quot;https://ChoiSeungWoo98.github.io/\u0026quot;\nbaseURL = \u0026quot;https://\u0026lt;username\u0026gt;.github.io/\u0026quot;\n다 설정했다면 로컬에서 테스트 해보자!\n$ hugo server 성공하면 아래와 같은 화면을 볼 수 있다. http://localhost:1313 접속하여 확인\n에러 로그 Error: module \"LoveIt\" not found; either add it as a Hugo Module or store it in \"/Users/\".: module does not exist 해당 로그가 뜬다면 themes 폴더 내부에 LoveIt이 없다는 소리다 확인 후 config.toml에서\nthemes = \"폴더명\" 으로 바꿔주자!\nError: module \"test\" not found; either add it as a Hugo Module or store it in \"/Users/\".: module does not exist test 폴더를 찾을 수 없다는 에러이다. 현재 LoveIt테마는 directory 주소를 설정 해주고 있다 이것을 제거해주자!\nconfig.toml 에서 아래 부분을 찾아서 제거\nthemes directory\n主题目录\nthemesDir = \"../..\"\nPC 이미지 mobile 이미지 Git Repository 연결 여태까지 노력해서 만든 블로그를 git이랑 연동해보자!\n1 2 3 4 5 6 7 8 9 10 11 # blog -\u0026gt; blog 레포지토리 연결 # git remote add origin http://github.com/\u0026lt;username\u0026gt;/blog.git $ git remote add origin https://github.com/choiseungwoo98/blog.git # blog/public -\u0026gt; \u0026lt;username\u0026gt;.github.io 연결 # 아래 코드를 수행하기 전에 blog 폴더에 public이 없는지 확인하자! 있으면 오류가 발생한다.... # git submodule add -b main http://github.com/\u0026lt;username\u0026gt;/\u0026lt;username\u0026gt;.github.io.git public # 만약 기존에 등록한 것이 있다면 git rm -r --cached public 를 입력해서 제거 후 등록 # 그래도 안된다면 강제로 하자.. # git submodule add -b main --force https://github.com/ChoiSeungWoo98/ChoiSeungWoo98.github.io.git public $ git submodule add -b main https://github.com/ChoiSeungWoo98/ChoiSeungWoo98.github.io.git public 게시글 작성 새로운 포스트를 만드는 것도 hugo에서 수행해준다.. hugo 짱..\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 아래 명령어를 입력하면 blog/content/posts/firstPost/test.md가 생성된다. 그걸 수정해서 글을 작성하면 된다! # hugo new posts/\u0026lt;원하는 패쓰\u0026gt;/파일 이름.md $ hugo new posts/firstPost/test.md Content \u0026#34;/Users/user/workspace/blog/content/posts/firstPost/test.md\u0026#34; created # 이제 게시글을 로컬에서 확인해보자! # 로컬 서버 실행 # draft: true로 설정 되어 있을때 hugo server로 실행하면 게시물이 보이지 않는다. # 따라서 아래 명령어로 서버를 실행해준다. 혹은 그냥 false로 두면 보임 # draft는 수정 중일때 true 수정 끝나면 false로 바꾸어야 github에 올라간다.. # http://localhost:1313 접속하여 확인 # 서버를 닫기 위해서는 ctrl + c 를 입력한다. $ hugo server -D 드디어 배포!!! 이제 배포만 하면 깃 블로그가 생성된다!! 배포를 진행해보자! 배포하지 않으면 여태 까지 한 작업 다 필요 없다는건 안 비밀..\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 작성한 프로젝트 빌드하기 # hugo -t \u0026lt;여러분의 테마\u0026gt; $ hugo -t loveit # 빌드가 완료되면 public에 파일들이 생긴다. 이 부분은 위에 submodule로 나눠서 관리 하기 때문에 # 해당 폴더로 이동 후 배포해줘야함.. $ cd public # 변경된 모든 파일 추가하기 $ git add . # 커밋 남기기! # 아래 코드로 커밋을 남기면 현재 시간 기준으로 커밋 메세지가 담김 꼭 이렇게 안해줘도 됨! $ msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # 현재 폴더 상태 확인하기 $ git status # 상태 확인하고 깨끗 하다면 커밋한 파일 배포해주기! $ git push origin main # blog 폴더로 이동하기 $ cd .. # blog 변경 사항 추가. public에서 배포한 부분도 여기서 다시 추가해줌 git add . # 추가한 사항 커밋 $ msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ] then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34; # blog 배포하기 $ git push origin main 배포가 완료 되었다면 git repository에서 build되는 과정을 확인하고 오류 없이 성공했다면 본인 블로그에 들어가서 확인 할 수 있다!\n블로그 주소 확인하기 블로그 주소를 모르겠다면\n1. username.github.io 레포지토리를 들어가기\n2. Settings에 들어가기\n3. Pages로 이동 후\n4. Visit site에서 확인 할 수 있다.\n보통 \"https://username.github.io/ 이러한 주소일 것이다.\n드디어 내 블로그 완성!!\n예쁘게 꾸미고 싶은 욕심이 많이 있기 때문에 추후에 커스텀 포스트로 찾아뵙겠습니다!! 😄\n포스트 작성 시 참고한 링크 정적 페이지 vs 동적 페이지 및 정적 페이지 비교 Hugo를 사용한 깃 블로그 만들기 ","date":"2023-03-04T14:16:49+09:00","permalink":"https://choiseungwoo98.github.io/p/blog-%EA%B9%83-%EB%B8%94%EB%A1%9C%EA%B7%B8-%EB%A7%8C%EB%93%9C%EB%8A%94-%EB%B0%A9%EB%B2%95/","title":"[Blog] 깃 블로그 만드는 방법"},{"content":"처음 써보는 깃 블로그 게시글 입니다.\n저는 이제 현업 3개월차 주주주주주주주주주주주니어 백엔드 개발자 입니다. :)\n블로그를 쓰려고 다짐한 이유는 제가 느끼는 것들과 공부한 부분을 글로 적고\n제 방식대로 이해하고 공부하기 위해 블로그를 작성 하자고 다짐하였습니다.\n앞으로 꾸준하고 열심히 적고 배우는 개발자가 되도록 노력하겠습니다.\n절대 이 마음 변치 않고 발전하는 개발자가 될 수 있도록!!\n화이팅!!!!!!\n","date":"2023-03-01T21:50:49+09:00","permalink":"https://choiseungwoo98.github.io/p/diary-%EA%B9%83-%EB%B8%94%EB%A1%9C%EA%B7%B8%EB%A5%BC-%EC%9E%91%EC%84%B1%ED%95%98%EA%B8%B0-%EC%A0%84-%EB%8B%A4%EC%A7%90/","title":"[Diary] 깃 블로그를 작성하기 전 다짐"}]